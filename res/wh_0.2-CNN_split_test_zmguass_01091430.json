{
    "eval_time": 91.7123351097107,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.2_pc",
            "patch_size": 13,
            "serve_patch_size": 13,
            "batch_size": 15,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "spectral_size": 270,
            "random_rotate": false,
            "noise_type": "zmguass"
        },
        "net": {
            "trainer": "CNN",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 100,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.2-CNN_split",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.2-CNN_split",
        "path_res": "./res/wh_0.2-CNN_split_test_zmguass_01091430",
        "path_pic": "./res/wh_0.2-CNN_split_test_zmguass_01091430.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.8034    0.8210    0.8121     11232\n           1     0.2054    0.9010    0.3345      2809\n           2     0.9024    0.5585    0.6900     17456\n           3     0.9827    0.6765    0.8013    130628\n           4     0.3796    0.0082    0.0161      4974\n           5     0.5806    0.0193    0.0374     35645\n           6     0.7553    0.0037    0.0073     19282\n           7     0.5151    0.0527    0.0957      3243\n           8     0.0890    1.0000    0.1634      8655\n           9     0.5620    0.3144    0.4032      9915\n          10     0.1875    0.0010    0.0020      8812\n          11     0.0000    0.0000    0.0000      7163\n          12     0.3805    0.0635    0.1088     18005\n          13     1.0000    0.0156    0.0308      5884\n          14     0.0000    0.0000    0.0000       801\n          15     0.4954    0.9738    0.6567      5809\n          16     0.5762    0.8916    0.7000      2408\n          17     0.0000    0.0000    0.0000      2573\n          18     0.0708    0.5454    0.1253      6969\n          19     0.1231    0.3562    0.1829      2788\n          20     0.0000    0.0000    0.0000      1062\n          21     0.0588    0.0037    0.0070      3232\n\n    accuracy                         0.4411    309345\n   macro avg     0.3940    0.3276    0.2352    309345\nweighted avg     0.7065    0.4411    0.4627    309345\n",
        "oa": 44.11353020090837,
        "confusion": "[[ 9222   314   731    34     0     0     0     0   779     0     0     0\n      0     0     0     0     9     0   127     0     0    16]\n [    4  2531    30     0     0     0     0     0    71     0     0     0\n      0     0     0     3   130     0     0    40     0     0]\n [   15  4375  9749    24     0     0     0     0  1143     0     0     0\n      0     0     0    17  1252     0   250   631     0     0]\n [  451   529     6 88364     0     0     0     0 40091     0     0     0\n      0     0     0     6     0     0   463   578     0   140]\n [ 1702  1846     6   985    41     0     0     0   188     0     0     0\n      0     0     0    14     0     0   146    12     0    34]\n [    8    50     0    22     2   688     1     0   708     1     4     0\n    265     0     0  2157     0     0 31631   108     0     0]\n [    0     8     0   159     0     0    71     0 17108    11     0     0\n     46     0     0    10     0     0   278  1591     0     0]\n [    2   238     4   125     9     0     0   171   496    35     0     0\n    326     0     0   362    10     0   447  1018     0     0]\n [    0     0     0     0     0     0     0     0  8655     0     0     0\n      0     0     0     0     0     0     0     0     0     0]\n [    0     0     0    20     0     0     1     0  5046  3117     0     0\n    289     0     0    92     0     0  1331    19     0     0]\n [    0     0     0   102     0     2    16     0  7964    48     9     0\n      6     0     0     4     0     0   643    18     0     0]\n [    1   146     8    15     0     0     1     0  2470    18     0     0\n     55     0     0   501     5     0  3738   203     0     2]\n [   72   591    18    41    56    20     1    39  2400     0     0     2\n   1143     0     0  2148    27     0  8829  2617     1     0]\n [    0   982   161     0     0   475     3   122   126  2316     2     0\n    872    92     0   185    12     0   424   112     0     0]\n [    2     0     0    10     0     0     0     0   614     0    33     0\n      0     0     0     0     0     0   142     0     0     0]\n [    0    32     0     0     0     0     0     0    12     0     0     0\n      0     0     0  5657   107     0     1     0     0     0]\n [    0     9     0     0     0     0     0     0     0     0     0     0\n      2     0     0   250  2147     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0  1219     0     0     0\n      0     0     0     0     0     0  1352     2     0     0]\n [    0     0     0     1     0     0     0     0  3156     0     0     0\n      0     0     0     8     0     0  3801     3     0     0]\n [    0     0     1     0     0     0     0     0  1773     0     0     0\n      0     0     0     0     0     0    21   993     0     0]\n [    0   671    89     0     0     0     0     0   121     0     0     0\n      0     0     0     6    27     0    76    72     0     0]\n [    0     0     0    16     0     0     0     0  3153     0     0     0\n      0     0     0     0     0     0     0    51     0    12]]",
        "each_acc": "[ 82.10470085  90.10323959  55.84899175  67.64552776   0.82428629\n   1.93014448   0.36821906   5.27289547 100.          31.43721634\n   0.10213345   0.           6.3482366    1.5635622    0.\n  97.38337063  89.16112957   0.          54.54154111  35.6169297\n   0.           0.37128713]",
        "aa": 32.755609635724404,
        "kappa": 34.88025417677183
    }
}