{
    "eval_time": 91.69497752189636,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.2_pc",
            "patch_size": 13,
            "serve_patch_size": 13,
            "batch_size": 15,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "spectral_size": 270,
            "random_rotate": false,
            "noise_type": "poisson"
        },
        "net": {
            "trainer": "CNN",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 100,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.2-CNN_split",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.2-CNN_split",
        "path_res": "./res/wh_0.2-CNN_split_test_poisson_01091434",
        "path_pic": "./res/wh_0.2-CNN_split_test_poisson_01091434.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     1.0000    0.1459    0.2547     11232\n           1     0.2706    0.6995    0.3903      2809\n           2     0.4335    0.9677    0.5988     17456\n           3     0.9396    0.5755    0.7138    130628\n           4     1.0000    0.0074    0.0148      4974\n           5     0.0000    0.0000    0.0000     35645\n           6     0.7763    0.3678    0.4991     19282\n           7     0.2598    0.5991    0.3624      3243\n           8     0.8985    0.1033    0.1853      8655\n           9     0.9668    0.0528    0.1002      9915\n          10     0.0000    0.0000    0.0000      8812\n          11     1.0000    0.0036    0.0072      7163\n          12     0.1152    0.4245    0.1812     18005\n          13     0.3171    0.2685    0.2908      5884\n          14     0.0000    0.0000    0.0000       801\n          15     1.0000    0.4565    0.6269      5809\n          16     0.5019    0.7566    0.6035      2408\n          17     0.0000    0.0000    0.0000      2573\n          18     1.0000    0.0146    0.0289      6969\n          19     0.0324    0.9928    0.0627      2788\n          20     0.0000    0.0000    0.0000      1062\n          21     0.0000    0.0000    0.0000      3232\n\n    accuracy                         0.3968    309345\n   macro avg     0.4778    0.2926    0.2237    309345\nweighted avg     0.6647    0.3968    0.4255    309345\n",
        "oa": 39.68126202136773,
        "confusion": "[[ 1639   712  8702    17     0     0     0     1     2     0     0     0\n    150     0     0     0     0     0     0     9     0     0]\n [    0  1965   767     0     0     0     0     0     0     0     0     0\n      0     0     0     0    71     0     0     6     0     0]\n [    0   236 16892     1     0     0     0     3     0     0     0     0\n      4    35     0     0     0     0     0   285     0     0]\n [    0   142  3029 75174     0     0     0   176     0     0     0     0\n     41    66     0     0     0     0     0 52000     0     0]\n [    0   494  3724   180    37     0     0    13     0     0     0     0\n      0     0     0     0     0     0     0   526     0     0]\n [    0   219    44     0     0     0     0   614     0     9     0     0\n  31768  1389     0     0     0     0     0  1602     0     0]\n [    0     7    81  1174     0     0  7091   667     0     0     0     0\n   7813   115     0     0     0     0     0  2334     0     0]\n [    0    79   784     0     0     0    97  1943     0     0     0     0\n     70   133     0     0     0     0     0   137     0     0]\n [    0     0     0     0     0     0     0     0   894     0     0     0\n      0     0     0     0     0     0     0  7761     0     0]\n [    0     0     0    37     0     0   299  1449     0   524     0     0\n   7206    39     0     0     0     0     0   361     0     0]\n [    0     6    14   902     0     0   497    65     0     0     0     0\n   1722     0     0     0     0     0     0  5606     0     0]\n [    0   391   162     0     0     0    24    75     0     0     0    26\n   5853    15     0     0     6     0     0   611     0     0]\n [    0  1353  3294     0     0     0    21   651     0     9     0     0\n   7643  1581     0     0     0     0     0  3452     1     0]\n [    0     6    83     0     0     0     0  1687     0     0     0     0\n   2527  1580     0     0     0     0     0     1     0     0]\n [    0     0    22   451     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0   328     0     0]\n [    0  1074   227     0     0     0     0     0    99     0     0     0\n      0     8     0  2652  1731     0     0    18     0     0]\n [    0   569     5     0     0     0     0     0     0     0     0     0\n      0    12     0     0  1822     0     0     0     0     0]\n [    0     0     9    38     0     0   704    52     0     0     0     0\n   1399     0     0     0     0     0     0   371     0     0]\n [    0     1     2     0     0     0     2    25     0     0     0     0\n    152     9     0     0     0     0   102  6676     0     0]\n [    0     0    20     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0  2768     0     0]\n [    0     7  1044     0     0     0     0     4     0     0     0     0\n      0     0     0     0     0     0     0     7     0     0]\n [    0     0    58  2030     0     0   399    54     0     0     0     0\n      0     0     0     0     0     0     0   691     0     0]]",
        "each_acc": "[14.59223647 69.95372019 96.76901925 57.548152    0.74386811  0.\n 36.77523079 59.91366019 10.32928943  5.28492184  0.          0.36297641\n 42.44931963 26.85248131  0.         45.65329661 75.66445183  0.\n  1.46362462 99.28263989  0.          0.        ]",
        "aa": 29.256313115857672,
        "kappa": 30.306938989902655
    }
}