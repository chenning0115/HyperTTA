{
    "epoch_loss": {
        "type": "index_value",
        "index": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10
        ],
        "value": [
            0.54554137630317,
            0.28423547225264834,
            0.21805099033491634,
            0.1778029649534119,
            0.15606487957749457,
            0.13593162407386475,
            0.1269005931616482,
            0.11630162015917875,
            0.11166178852667964,
            0.10067522083450389
        ]
    },
    "train_oa": {
        "type": "index_value",
        "index": [
            10
        ],
        "value": [
            97.21573001018281
        ]
    },
    "train_aa": {
        "type": "index_value",
        "index": [
            10
        ],
        "value": [
            95.59693230045562
        ]
    },
    "train_kappa": {
        "type": "index_value",
        "index": [
            10
        ],
        "value": [
            96.48389188278738
        ]
    },
    "max_oa": {
        "type": "index_value",
        "index": [
            10
        ],
        "value": [
            97.21573001018281
        ]
    },
    "eval_time": 158.77800512313843,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.2_pc",
            "patch_size": 13,
            "serve_patch_size": 13,
            "batch_size": 15,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "spectral_size": 240,
            "random_rotate": false,
            "noise_type": "clean"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 10,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.2-noPCA_split",
        "train_sign": "train",
        "path_model_save": "./save_models/wh_0.2-noPCA_split",
        "path_res": "./res/wh_0.2-noPCA_split_01091030",
        "path_pic": "./res/wh_0.2-noPCA_split_01091030.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.9975    0.9810    0.9892     11232\n           1     0.9501    0.9352    0.9426      2809\n           2     0.9908    0.7278    0.8392     17456\n           3     0.9984    0.9992    0.9988    130628\n           4     0.9441    0.9708    0.9573      4974\n           5     0.9859    0.9990    0.9924     35645\n           6     0.9636    0.9873    0.9753     19282\n           7     0.9580    0.8862    0.9207      3243\n           8     0.9986    0.9844    0.9914      8655\n           9     0.9968    0.9337    0.9642      9915\n          10     0.9636    0.9927    0.9780      8812\n          11     0.9837    0.9120    0.9465      7163\n          12     0.9614    0.9904    0.9757     18005\n          13     0.9289    0.9990    0.9627      5884\n          14     0.9960    0.9276    0.9606       801\n          15     0.9979    0.9845    0.9912      5809\n          16     0.9654    0.9975    0.9812      2408\n          17     0.9778    0.9425    0.9598      2573\n          18     0.9860    0.9384    0.9616      6969\n          19     0.9621    0.9641    0.9631      2788\n          20     0.1935    1.0000    0.3243      1062\n          21     0.9835    0.9777    0.9806      3232\n\n    accuracy                         0.9722    309345\n   macro avg     0.9402    0.9560    0.9344    309345\nweighted avg     0.9838    0.9722    0.9757    309345\n",
        "oa": 97.21573001018281,
        "confusion": "[[ 11019     56      1      4    150      2      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [    28   2627    104      0     36      0      0      6      0      0\n       0      6      0      0      0      1      1      0      0      0\n       0      0]\n [     0     80  12705     32     62     14      6     41      1      0\n       7     21     18     53      0      0      0      0      0     87\n    4329      0]\n [     0      2      9 130523     38      0     51      0      0      0\n       0      0      2      0      0      0      0      0      0      0\n       3      0]\n [     0      0      0     95   4829      0      0      0      0      0\n       0      0     49      0      0      0      0      0      1      0\n       0      0]\n [     0      0      0      0      0  35610      0      1      0      0\n       0      0     29      3      0      0      0      0      2      0\n       0      0]\n [     0      0      0      1      0      1  19037     36      0      0\n      38     27     74     21      3      0      0      0     10      3\n       1     30]\n [     0      0      1      5      0      0    118   2874      0      0\n       1      6     87     56      0      0      5      0      0      0\n      87      3]\n [     0      0      3      0      0      0     22      0   8520      9\n      19      0      0      0      0      5      0      0     67      0\n       0     10]\n [     0      0      0      0      0    215     45      2      0   9258\n      25     16      5    299      0      0      0     49      1      0\n       0      0]\n [     0      0      0     20      0      0     16      6      0      3\n    8748      1      5      0      0      0      0      0      1      5\n       0      7]\n [     0      0      0      0      0      2    267      0      0      0\n      91   6533    265      0      0      1      3      1      0      0\n       0      0]\n [     0      0      0     10      0     54     38     21      0      0\n       0     25  17832     18      0      0      0      5      0      2\n       0      0]\n [     0      0      0      0      0      0      3      0      0      3\n       0      0      0   5878      0      0      0      0      0      0\n       0      0]\n [     0      0      0      0      0      0     23      1      3      0\n      31      0      0      0    743      0      0      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      5      8      0\n       0      0      0      0      0   5719     77      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      0      0\n       0      2      0      0      0      4   2402      0      0      0\n       0      0]\n [     0      0      0      1      0      0     11      1      0      9\n       1      3    119      0      0      0      0   2425      0      0\n       0      3]\n [     0      0      0     10      0    215     46      6      0      6\n      84      1     50      0      0      0      0      0   6540      9\n       2      0]\n [     0      0      0     30      0      6      2      0      0      0\n      33      0     13      0      0      1      0      0     11   2688\n       4      0]\n [     0      0      0      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n    1062      0]\n [     0      0      0      1      0      0     71      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0   3160]]",
        "each_acc": "[ 98.10363248  93.52082592  72.78299725  99.91961907  97.08484117\n  99.90180951  98.72938492  88.62164662  98.44020797  93.37367625\n  99.27371766  91.20480246  99.03915579  99.89802855  92.75905119\n  98.45067998  99.75083056  94.24795958  93.84416703  96.41319943\n 100.          97.77227723]",
        "aa": 95.59693230045562,
        "kappa": 96.48389188278738
    }
}