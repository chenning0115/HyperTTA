{
    "eval_time": 91.81007313728333,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.2_pc",
            "patch_size": 13,
            "serve_patch_size": 13,
            "batch_size": 15,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "spectral_size": 270,
            "random_rotate": false,
            "noise_type": "salt_pepper"
        },
        "net": {
            "trainer": "CNN",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 100,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.2-CNN_split",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.2-CNN_split",
        "path_res": "./res/wh_0.2-CNN_split_test_salt_pepper_01091426",
        "path_pic": "./res/wh_0.2-CNN_split_test_salt_pepper_01091426.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.6776    0.9698    0.7978     11232\n           1     0.2194    0.9106    0.3536      2809\n           2     0.9619    0.4895    0.6488     17456\n           3     0.9876    0.9128    0.9487    130628\n           4     0.4292    0.0810    0.1363      4974\n           5     0.9642    0.2654    0.4162     35645\n           6     0.7951    0.0507    0.0954     19282\n           7     0.6229    0.2165    0.3213      3243\n           8     0.1848    1.0000    0.3119      8655\n           9     0.6075    0.7688    0.6787      9915\n          10     0.3628    0.0428    0.0765      8812\n          11     0.4808    0.0035    0.0069      7163\n          12     0.4406    0.2953    0.3536     18005\n          13     0.9853    0.1710    0.2914      5884\n          14     0.4000    0.0075    0.0147       801\n          15     0.4842    0.9656    0.6450      5809\n          16     0.4296    0.9572    0.5930      2408\n          17     0.0000    0.0000    0.0000      2573\n          18     0.1056    0.6063    0.1798      6969\n          19     0.2122    0.6291    0.3174      2788\n          20     0.5370    0.0273    0.0520      1062\n          21     0.2727    0.0009    0.0019      3232\n\n    accuracy                         0.6133    309345\n   macro avg     0.5073    0.4260    0.3291    309345\nweighted avg     0.7850    0.6133    0.6117    309345\n",
        "oa": 61.3273206290711,
        "confusion": "[[ 10893    173     73     19      1      0      0      0     50      0\n       0      0      0      0      0      3      6      0     14      0\n       0      0]\n [    13   2558     15      0      0      0      0      0     47      0\n       0      0      0      0      0      3    154      0      6     13\n       0      0]\n [    53   5164   8545     27      3      0      8     66    249      0\n       0      0      2      7      9     43   2635      0    167    474\n       4      0]\n [  2084    199      3 119242    238      0      0      0   8209      0\n       6      0     12      0      0      9      0      0    362    261\n       0      3]\n [  2808   1392      8    327    403      0      0      0      8      0\n       0      0      0      0      0     12      0      0      3     13\n       0      0]\n [    25     24      0     28     34   9459      0     13    272    133\n      29      0   3026      0      0   2976      0      0  19545     81\n       0      0]\n [     5     13      9    345      4      0    978      8  14167    137\n      38      0    692      0      0     16      0      0    594   2273\n       0      3]\n [    15    222     29     14     21      0     18    702    161     39\n       4      7    779      2      0    267     10      0    355    598\n       0      0]\n [     0      0      0      0      0      0      0      0   8655      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [     0      0      0     11      0      0     10      0   1188   7623\n      11      0    298      0      0     91      0      0    683      0\n       0      0]\n [    22      0      0    219      0      2     57      0   6090    405\n     377      0    360      0      0      4      0      0   1241     35\n       0      0]\n [     2    100      4     58      2      0    128      5    493   1734\n      30     25    320      0      0    520      0      0   3431    311\n       0      0]\n [   132    382     40     58    230    294      6    161    319     56\n      10     20   5316      5      0   1731     25      0   7013   2186\n      21      0]\n [     0    814     70      0      0     54      9    144      6   2415\n       5      0   1235   1006      0     84      7      0     28      7\n       0      0]\n [     0      0      0     14      0      0      0      0    223      0\n     514      0      0      0      6      0      0      0     33     11\n       0      0]\n [     0     30      0      0      0      0      0      0      3      0\n       0      0      0      0      0   5609    165      0      0      0\n       0      2]\n [     0      3      0      0      0      0      0      0      0      0\n       0      0      0      0      0    100   2305      0      0      0\n       0      0]\n [     0      0      0      1      0      1     11      0    300      7\n       9      0      3      0      0      7      0      0   2177     57\n       0      0]\n [     2      0      0      4      1      0      0      0   2694      0\n       0      0      0      0      0     12      0      0   4225     31\n       0      0]\n [     0     30      1      0      0      0      0      0    983      0\n       0      0      0      0      0      1      0      0     19   1754\n       0      0]\n [    22    557     86      1      2      0      2     28      3      0\n       4      0     23      1      0     95     59      0     78     72\n      29      0]\n [     0      0      0    374      0      0      3      0   2720      0\n       2      0      0      0      0      0      0      0     43     87\n       0      3]]",
        "each_acc": "[9.69818376e+01 9.10644357e+01 4.89516499e+01 9.12836452e+01\n 8.10213108e+00 2.65366812e+01 5.07208796e+00 2.16466235e+01\n 1.00000000e+02 7.68835098e+01 4.27825692e+00 3.49015776e-01\n 2.95251319e+01 1.70972128e+01 7.49063670e-01 9.65570666e+01\n 9.57225914e+01 0.00000000e+00 6.06256278e+01 6.29124821e+01\n 2.73069680e+00 9.28217822e-02]",
        "aa": 42.598298607694026,
        "kappa": 52.570888894368885
    }
}