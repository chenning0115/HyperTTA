{
    "eval_time": 91.878422498703,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.2_pc",
            "patch_size": 13,
            "serve_patch_size": 13,
            "batch_size": 15,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "spectral_size": 270,
            "random_rotate": false,
            "noise_type": "kernal"
        },
        "net": {
            "trainer": "CNN",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 100,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.2-CNN_split",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.2-CNN_split",
        "path_res": "./res/wh_0.2-CNN_split_test_kernal_01091427",
        "path_pic": "./res/wh_0.2-CNN_split_test_kernal_01091427.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     1.0000    0.0005    0.0011     11232\n           1     0.0412    0.8380    0.0785      2809\n           2     0.8047    0.1601    0.2670     17456\n           3     0.9895    0.8210    0.8974    130628\n           4     0.0620    0.0082    0.0146      4974\n           5     0.0000    0.0000    0.0000     35645\n           6     0.3133    0.0108    0.0209     19282\n           7     0.6480    0.1748    0.2754      3243\n           8     0.5593    0.9152    0.6943      8655\n           9     0.0000    0.0000    0.0000      9915\n          10     0.0000    0.0000    0.0000      8812\n          11     0.0000    0.0000    0.0000      7163\n          12     0.1265    0.6147    0.2098     18005\n          13     0.0000    0.0000    0.0000      5884\n          14     0.0000    0.0000    0.0000       801\n          15     1.0000    0.1171    0.2096      5809\n          16     0.2439    0.4751    0.3223      2408\n          17     0.0000    0.0000    0.0000      2573\n          18     0.0000    0.0000    0.0000      6969\n          19     0.0780    0.8587    0.1430      2788\n          20     0.0000    0.0000    0.0000      1062\n          21     0.0000    0.0000    0.0000      3232\n\n    accuracy                         0.4410    309345\n   macro avg     0.2667    0.2270    0.1424    309345\nweighted avg     0.5716    0.4410    0.4386    309345\n",
        "oa": 44.10189270878792,
        "confusion": "[[     6   9455    530     39      0      0      0      2     24      0\n       0      0     29      0      0      0   1147      0      0      0\n       0      0]\n [     0   2354     10      0      0      0      0      0      0      0\n       0      0      0      0      0      0    445      0      0      0\n       0      0]\n [     0  14414   2794      0      0      0      0      0      0      0\n       0      0    196      0      0      0      2      0      0     50\n       0      0]\n [     0  12066     82 107250    620      0      0     22      0      0\n       0      0      1      0      0      0      0      0      0  10587\n       0      0]\n [     0   4726     50    128     41      0      0     24      0      0\n       0      0      2      0      0      0      0      0      0      3\n       0      0]\n [     0   1665      0      0      0      0      0      0      3      0\n       0      0  33259      0      0      0      4      0      0    714\n       0      0]\n [     0     93      0     63      0      0    208     51      5      0\n      33      0  16010      0      0      0      0      0      0   2819\n       0      0]\n [     0    963      0      0      0      0      0    567      0      0\n       0      0   1585      0      0      0      0      0      0    128\n       0      0]\n [     0      1      0      0      0      0      0      0   7921      0\n       0      0      0      0      0      0      0      0      0    733\n       0      0]\n [     0     10      0      0      0      0      0      0     16      0\n       0      0   9823      0      0      0      0      0      0     66\n       0      0]\n [     0      8      0     31      0      0    238      0    199      0\n       0      0   2197      0      0      0      0      0      0   6139\n       0      0]\n [     0    473      0     48      0      0     14      0      0      0\n     331      0   6155      0      0      0      0      0      0    142\n       0      0]\n [     0   5731      0     29      0      0      0    169      0      0\n       0      0  11068      0      0      0     17      0      0    991\n       0      0]\n [     0   1650      0      0      0      0      0     40      0      0\n       0      0   4194      0      0      0      0      0      0      0\n       0      0]\n [     0      2      0      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0    799\n       0      0]\n [     0    909      6      0      0      0      0      0   2251      0\n       0      0     30      0      0    680   1932      0      0      1\n       0      0]\n [     0   1264      0      0      0      0      0      0      0      0\n       0      0      0      0      0      0   1144      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      0      0\n       0      0   1996      0      0      0      0      0      0    577\n       0      0]\n [     0     29      0      0      0      0    204      0   3500      0\n       0      0    498      0      0      0      0      0      0   2738\n       0      0]\n [     0    386      0      0      0      0      0      0      0      0\n       0      0      8      0      0      0      0      0      0   2394\n       0      0]\n [     0    982      0      0      0      0      0      0      0      0\n       0      0     80      0      0      0      0      0      0      0\n       0      0]\n [     0      0      0    802      0      0      0      0    243      0\n       0      0    376      0      0      0      0      0      0   1811\n       0      0]]",
        "each_acc": "[5.34188034e-02 8.38020648e+01 1.60059578e+01 8.21033775e+01\n 8.24286289e-01 0.00000000e+00 1.07872627e+00 1.74838113e+01\n 9.15193530e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 6.14718134e+01 0.00000000e+00 0.00000000e+00 1.17059735e+01\n 4.75083056e+01 0.00000000e+00 0.00000000e+00 8.58680057e+01\n 0.00000000e+00 0.00000000e+00]",
        "aa": 22.701140638468722,
        "kappa": 32.70954708578616
    }
}