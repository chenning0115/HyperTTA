{
    "epoch_loss": {
        "type": "index_value",
        "index": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            16,
            17,
            18,
            19,
            20
        ],
        "value": [
            0.2749256027895175,
            0.07831470693992268,
            0.05405728826121135,
            0.045392889496769215,
            0.03714504783119305,
            0.035903986404717814,
            0.032616873624259766,
            0.029062931543013135,
            0.029245002748416505,
            0.02300831783739749,
            0.02669974935371424,
            0.025079078430379355,
            0.023508897516614616,
            0.01895625698949006,
            0.021683517025047245,
            0.017653002979321382,
            0.019124234247497752,
            0.017290729680896164,
            0.017940828088877314,
            0.015402977376490832
        ]
    },
    "train_oa": {
        "type": "index_value",
        "index": [
            10,
            20
        ],
        "value": [
            99.25807369264942,
            99.25807369264942
        ]
    },
    "train_aa": {
        "type": "index_value",
        "index": [
            10,
            20
        ],
        "value": [
            98.40005735066003,
            98.59510469248747
        ]
    },
    "train_kappa": {
        "type": "index_value",
        "index": [
            10,
            20
        ],
        "value": [
            99.06249737740318,
            99.06273748223992
        ]
    },
    "max_oa": {
        "type": "index_value",
        "index": [
            10,
            20
        ],
        "value": [
            99.25807369264942,
            99.25807369264942
        ]
    },
    "eval_time": 164.60925436019897,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.1_pc",
            "patch_size": 25,
            "serve_patch_size": 25,
            "batch_size": 32,
            "num_classes": 22,
            "pca": 30,
            "dim_heads": 64,
            "spectral_size": 30,
            "random_rotate": false,
            "noise_type": "clean"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 20,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.1_split",
        "train_sign": "train",
        "path_model_save": "./save_models/wh_0.1_split",
        "path_res": "./res/wh_0.1_split_12241639",
        "path_pic": "./res/wh_0.1_split_12241639.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.9855    0.9975    0.9914     12636\n           1     0.9361    0.9411    0.9386      3160\n           2     0.9980    0.9836    0.9907     19638\n           3     0.9992    0.9990    0.9991    146956\n           4     0.9713    0.9927    0.9819      5596\n           5     0.9989    0.9987    0.9988     40101\n           6     0.9899    0.9905    0.9902     21692\n           7     0.9761    0.9967    0.9863      3648\n           8     0.9840    0.9995    0.9917      9737\n           9     0.9805    0.9954    0.9879     11154\n          10     0.9942    0.9302    0.9611      9913\n          11     0.9990    0.9731    0.9859      8058\n          12     0.9959    0.9886    0.9922     20256\n          13     0.9930    0.9693    0.9810      6620\n          14     0.6190    0.9756    0.7574       901\n          15     0.9989    0.9982    0.9985      6535\n          16     0.9956    0.9978    0.9967      2709\n          17     0.9642    0.9969    0.9803      2895\n          18     0.9870    0.9911    0.9891      7840\n          19     0.9816    0.9860    0.9838      3137\n          20     0.9449    0.9900    0.9669      1195\n          21     0.9859    0.9997    0.9928      3636\n\n    accuracy                         0.9926    348013\n   macro avg     0.9672    0.9860    0.9746    348013\nweighted avg     0.9932    0.9926    0.9927    348013\n",
        "oa": 99.25807369264942,
        "confusion": "[[ 12604     10      0     22      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [   170   2974      6      0      9      0      0      1      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [     1    156  19316      4     15      0      5      0     93      0\n       3      2      4      0      0      0      0      0      0     22\n      17      0]\n [     2      3     14 146803    133      0      0      0      0      0\n       0      0      1      0      0      0      0      0      0      0\n       0      0]\n [     0      0      0     12   5555      0      0      0      0      0\n       0      0      3      0      0      0      0      0     26      0\n       0      0]\n [     0      0      0      4      0  40047      0      0      0      0\n       3      0     11      0      0      0      0      0     34      2\n       0      0]\n [     0      5      0     42      3      0  21485     25     37      1\n      14      4      6      2      7      0      0      0     25      0\n       9     27]\n [     3      0      0      0      0      0      5   3636      0      0\n       0      0      1      0      0      0      0      0      0      0\n       0      3]\n [     0      0      0      0      0      0      0      0   9732      4\n       0      0      0      0      0      1      0      0      0      0\n       0      0]\n [     0      0      0      0      0      6      0      0      1  11103\n       0      0      0      0      0      0      0     44      0      0\n       0      0]\n [     0      0      0     15      0      0     22      0      7     72\n    9221      0      0      2    516      0      0     12      0     21\n       7     18]\n [     0      5      5      0      0      0    144      2      0      7\n       1   7841     47      0      0      1      0      1      0      0\n       0      4]\n [    10      0      0      9      4     23     11     29      0     28\n       6      0  20025     41      0      2      1     50     16      0\n       1      0]\n [     0     23     14      0      0      0     19     20      0     91\n       0      1      0   6417      0      0      0      0      0      0\n      35      0]\n [     0      0      0      0      0      0     11      0     11      0\n       0      0      0      0    879      0      0      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      0      0\n       0      1      0      0      0   6523     11      0      0      0\n       0      0]\n [     0      1      0      0      0      0      0      0      0      0\n       0      0      2      0      0      3   2703      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      3      3\n       0      0      3      0      0      0      0   2886      0      0\n       0      0]\n [     0      0      0      6      0     16      2      0      6     15\n       8      0      4      0      0      0      0      0   7770     13\n       0      0]\n [     0      0      0      4      0      1      1      0      0      0\n      19      0      0      0     18      0      0      0      1   3093\n       0      0]\n [     0      0      0      0      0      0      0     12      0      0\n       0      0      0      0      0      0      0      0      0      0\n    1183      0]\n [     0      0      0      1      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0   3635]]",
        "each_acc": "[99.7467553  94.11392405 98.36032183 99.8958872  99.26733381 99.86534002\n 99.04573115 99.67105263 99.94864948 99.54276493 93.01926763 97.30702408\n 98.85959716 96.93353474 97.55826859 99.81637337 99.77851606 99.68911917\n 99.10714286 98.59738604 98.9958159  99.97249725]",
        "aa": 98.59510469248747,
        "kappa": 99.06273748223992
    }
}