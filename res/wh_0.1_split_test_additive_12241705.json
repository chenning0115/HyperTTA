{
    "eval_time": 164.2161509990692,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.1_pc",
            "patch_size": 25,
            "serve_patch_size": 25,
            "batch_size": 32,
            "num_classes": 22,
            "pca": 30,
            "dim_heads": 64,
            "spectral_size": 30,
            "random_rotate": false,
            "noise_type": "additive"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 10,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.1_split",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.1_split",
        "path_res": "./res/wh_0.1_split_test_additive_12241705",
        "path_pic": "./res/wh_0.1_split_test_additive_12241705.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.8249    0.5525    0.6617     12636\n           1     0.2629    0.7063    0.3832      3160\n           2     0.9447    0.5050    0.6582     19638\n           3     0.7676    0.9906    0.8650    146956\n           4     0.3483    0.0747    0.1230      5596\n           5     0.9070    0.6563    0.7616     40101\n           6     0.1154    0.0004    0.0008     21692\n           7     0.1431    0.0885    0.1094      3648\n           8     0.5908    0.9173    0.7187      9737\n           9     0.2217    0.9644    0.3605     11154\n          10     0.4474    0.0034    0.0068      9913\n          11     0.0443    0.0042    0.0077      8058\n          12     0.4218    0.5475    0.4765     20256\n          13     0.0569    0.0364    0.0444      6620\n          14     0.0000    0.0000    0.0000       901\n          15     0.1765    0.0129    0.0240      6535\n          16     0.3037    0.1776    0.2241      2709\n          17     0.0000    0.0000    0.0000      2895\n          18     0.1062    0.0015    0.0030      7840\n          19     0.1849    0.0669    0.0983      3137\n          20     0.0000    0.0000    0.0000      1195\n          21     0.0000    0.0000    0.0000      3636\n\n    accuracy                         0.6427    348013\n   macro avg     0.3122    0.2867    0.2512    348013\nweighted avg     0.6014    0.6427    0.5846    348013\n",
        "oa": 64.26656475476491,
        "confusion": "[[  6981   2096      0   3411    121     26      0      0      0      0\n       0      0      1      0      0      0      0      0      0      0\n       0      0]\n [     6   2232     86    764     65      0      0      0      0      0\n       0      0      2      0      0      3      0      1      0      1\n       0      0]\n [    15   2799   9917   6572      0      3      0      5    119     14\n       0      1     60      0      0     20      5      0      4    104\n       0      0]\n [   844      3      0 145580    511      0      0     11      0      6\n       0      0      0      0      0      0      0      1      0      0\n       0      0]\n [   445     72      0   4634    418      2      0      3      0     11\n       4      0      6      0      0      0      0      1      0      0\n       0      0]\n [    44      1      0    180      4  26320      5    378      2   5304\n       9     19   3844   3984      0      0      0      0      4      3\n       0      0]\n [     0      3      6   7990      1      8      9     43   5469   6706\n       3     91   1082      0      9      9      0      0      1    261\n       0      1]\n [    52    108     40   1290      0    416      8    323      7     93\n       6      6   1147      0      3     16     53      0     15     64\n       0      1]\n [     0      0      0     57      0      0      1      1   8932    733\n       0      1      8      0      0      0      0      1      0      3\n       0      0]\n [     0      0      0    102      0     58      0      4      0  10757\n       2      9    207      0      0      0      0      0      0     15\n       0      0]\n [     0      0      1   5401      0      1      5     20    413   3631\n      34      6    216      0      2      0      0      0      3    180\n       0      0]\n [     0     54      0    533      0      1      2     63     27   6371\n       5     34    842      0      2     30     11      0     24     59\n       0      0]\n [    74    156    118   3199     78   2145     43   1389     32   1518\n       6    105  11091     10      0    107      3      0     38    144\n       0      0]\n [     0     59     96   1068      0     21      0      0      3   4427\n       0     13    649    241      0      3     22      0     10      8\n       0      0]\n [     0      0      0    832      0      0      0      0     25     17\n       0      0      1      0      0      0      0      0      0     26\n       0      0]\n [     0     70      0      0      0      1      0      0     12    149\n       0    422   4786      0      0     84   1005      5      1      0\n       0      0]\n [     0    451      0      1      0      0      0      0      1      1\n       0     28   1603      0      0    143    481      0      0      0\n       0      0]\n [     2      0      0   1050      0     10      4     16      2   1320\n       5      1    457      0      8      0      0      0      0     20\n       0      0]\n [     0      3      6    413      1      7      1      1     40   7107\n       1     30    203      0      0      1      0      0     12     14\n       0      0]\n [     0     84    110   2246      0      0      0      0     33    316\n       1      2     84      0      2     48      0      0      1    210\n       0      0]\n [     0    298    117    734      1      0      0      0      0      3\n       0      0      5      0      0     12      4      0      0     21\n       0      0]\n [     0      0      0   3596      0      0      0      0      1     36\n       0      0      0      0      0      0      0      0      0      3\n       0      0]]",
        "each_acc": "[5.52469136e+01 7.06329114e+01 5.04990325e+01 9.90636653e+01\n 7.46962116e+00 6.56342735e+01 4.14899502e-02 8.85416667e+00\n 9.17325665e+01 9.64407387e+01 3.42983960e-01 4.21940928e-01\n 5.47541469e+01 3.64048338e+00 0.00000000e+00 1.28538638e+00\n 1.77556294e+01 0.00000000e+00 1.53061224e-01 6.69429391e+00\n 0.00000000e+00 0.00000000e+00]",
        "aa": 28.666513879521105,
        "kappa": 52.15499394312183
    }
}