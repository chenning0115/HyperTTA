{
    "eval_time": 156.16811752319336,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.2_pc",
            "patch_size": 13,
            "serve_patch_size": 13,
            "batch_size": 15,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "spectral_size": 240,
            "random_rotate": false,
            "noise_type": "additive"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 10,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.2-noPCA_split",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.2-noPCA_split",
        "path_res": "./res/wh_0.2-noPCA_split_test_additive_01091055",
        "path_pic": "./res/wh_0.2-noPCA_split_test_additive_01091055.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.6598    0.9917    0.7924     11232\n           1     0.6737    0.8982    0.7699      2809\n           2     0.9976    0.5317    0.6937     17456\n           3     0.9903    0.9322    0.9603    130628\n           4     0.6994    0.3967    0.5062      4974\n           5     0.8198    0.9549    0.8822     35645\n           6     0.7805    0.1473    0.2479     19282\n           7     0.6388    0.2165    0.3234      3243\n           8     0.4685    0.9785    0.6336      8655\n           9     0.9648    0.7301    0.8312      9915\n          10     0.7390    0.4459    0.5562      8812\n          11     0.8821    0.0627    0.1170      7163\n          12     0.8936    0.5116    0.6507     18005\n          13     0.9993    0.2437    0.3919      5884\n          14     0.9980    0.6130    0.7595       801\n          15     0.8432    0.9964    0.9134      5809\n          16     0.8096    0.9306    0.8659      2408\n          17     0.0000    0.0000    0.0000      2573\n          18     0.1683    0.9897    0.2877      6969\n          19     0.2178    0.9254    0.3526      2788\n          20     0.0951    0.0367    0.0530      1062\n          21     0.6939    0.1866    0.2941      3232\n\n    accuracy                         0.7553    309345\n   macro avg     0.6833    0.5782    0.5401    309345\nweighted avg     0.8602    0.7553    0.7561    309345\n",
        "oa": 75.52506101601772,
        "confusion": "[[ 11139     54      0      0      1      2      0      0      0      0\n       0      0      0      0      0      0      0      0     36      0\n       0      0]\n [   163   2523      2      0      4      0      0      1      2      0\n       0      0      0      0      0      2     60      0      0     52\n       0      0]\n [  1372   1063   9281      7    681     19      0      4     48      0\n       1      1     23      0      0     32    237      0     32   4284\n     371      0]\n [  1634      8      1 121767     64      0      0      0     98      0\n       0      0      0      0      0      0      0      0   6585    471\n       0      0]\n [  2397      6      0    436   1973      0      0      0      0      0\n       0      0      0      0      0     10      0      0     90     62\n       0      0]\n [     0      0      0      0      0  34036      0      0      0      0\n       0      0    197      0      0     61      0      0   1349      2\n       0      0]\n [    72      1      0     98      0    116   2841      0   7877    123\n     607      2     17      0      1     16      0      0   6633    618\n       0    260]\n [    12      0      0     10      4    865    371    702     10      1\n      37      2    150      1      0     42     12      0    280    738\n       0      6]\n [     0      0      0      0      0      0      0      0   8469      0\n       0      0      0      0      0     11      0      0    170      5\n       0      0]\n [     0      0      0      0      0    972      8      0     64   7239\n      97      0      4      0      0     25      0      0   1499      7\n       0      0]\n [     0      0      0    174      0     77    220      0    369     76\n    3929     11      4      0      0      0      0      0   3698    254\n       0      0]\n [     0      0      0      0      0    148     95      3      9      3\n      22    449    236      0      0    190     59      0   5769    180\n       0      0]\n [     0      0      0     78     21   1860     63     80      0      1\n      10     34   9212      0      0    301      3      0   4731   1611\n       0      0]\n [     0      0      1      0      0   3422      0    305      0     58\n      13     10    257   1434      0    198    108      0     12     66\n       0      0]\n [     0      3      0      2      0      0      0      3     40      0\n     229      0      0      0    491      0      0      0      0     33\n       0      0]\n [     0      0      0      0      0      0      0      0      5      0\n       0      0      0      0      0   5788     15      0      0      1\n       0      0]\n [     0      1      0      0      0      0      0      0      0      0\n       0      0      0      0      0    166   2241      0      0      0\n       0      0]\n [     0      0      0      0      0      2     41      0      6      2\n     207      0      7      0      0      0      0      0   2181    127\n       0      0]\n [     0      0      0      0      0      0      0      0      8      0\n       0      0      0      0      0      0      0      0   6897     64\n       0      0]\n [     0      1      0      0      0      0      1      0     62      0\n       0      0      7      0      0      1      0      0    136   2580\n       0      0]\n [     3     85     18      0     73      0      0      1      0      0\n       0      0    195      0      0     21     33      0     11    583\n      39      0]\n [    91      0      0    391      0      0      0      0   1011      0\n     165      0      0      0      0      0      0      0    862    109\n       0    603]]",
        "each_acc": "[99.17200855 89.81844073 53.16796517 93.21661512 39.66626458 95.48604292\n 14.73394876 21.6466235  97.85095321 73.01059002 44.58692692  6.26832333\n 51.16356568 24.37117607 61.29837703 99.638492   93.06478405  0.\n 98.96685321 92.53945481  3.67231638 18.65717822]",
        "aa": 57.81804091939517,
        "kappa": 69.52655495633294
    }
}