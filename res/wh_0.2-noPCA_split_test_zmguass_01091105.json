{
    "eval_time": 155.6508138179779,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.2_pc",
            "patch_size": 13,
            "serve_patch_size": 13,
            "batch_size": 15,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "spectral_size": 240,
            "random_rotate": false,
            "noise_type": "zmguass"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 10,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.2-noPCA_split",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.2-noPCA_split",
        "path_res": "./res/wh_0.2-noPCA_split_test_zmguass_01091105",
        "path_pic": "./res/wh_0.2-noPCA_split_test_zmguass_01091105.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.7865    0.7210    0.7523     11232\n           1     0.0540    0.9537    0.1022      2809\n           2     0.5287    0.0095    0.0187     17456\n           3     0.9960    0.5597    0.7167    130628\n           4     0.7329    0.0215    0.0418      4974\n           5     0.7782    0.2829    0.4150     35645\n           6     0.6241    0.0091    0.0180     19282\n           7     0.7853    0.0395    0.0752      3243\n           8     0.1649    0.9933    0.2829      8655\n           9     0.8110    0.5685    0.6684      9915\n          10     0.3089    0.0043    0.0085      8812\n          11     0.0214    0.0006    0.0011      7163\n          12     0.4980    0.0417    0.0770     18005\n          13     1.0000    0.0092    0.0182      5884\n          14     1.0000    0.0312    0.0605       801\n          15     0.3455    0.9869    0.5118      5809\n          16     0.4199    0.8812    0.5687      2408\n          17     0.0000    0.0000    0.0000      2573\n          18     0.0753    0.5834    0.1333      6969\n          19     0.0827    0.7565    0.1491      2788\n          20     0.0000    0.0000    0.0000      1062\n          21     0.0000    0.0000    0.0000      3232\n\n    accuracy                         0.3998    309345\n   macro avg     0.4551    0.3388    0.2100    309345\nweighted avg     0.7308    0.3998    0.4353    309345\n",
        "oa": 39.98383681649938,
        "confusion": "[[ 8098  2954    50     6    18     0     0     0     2     0     0     0\n      0     0     0    43     0     0    61     0     0     0]\n [   27  2679     0     0     0     0     0     0     0     0     0     0\n      0     0     0     2    86     0     0    15     0     0]\n [    0 15454   166     0     0     0     0     0    39     0     0     0\n      0     0     0    68   711     0     4  1014     0     0]\n [ 1536 23580    88 73114    21     0     0     0 12790     0     0     0\n      0     0     0    12     0     0  9545  9942     0     0]\n [  635  3688     0   168   107     0     0     0     0     0     0     0\n      0     0     0    29    13     0   120   214     0     0]\n [    0     0     0     0     0 10084     2     2    17    16     0     0\n    257     0     0  2801    16     0 22079   371     0     0]\n [    0    89     0    37     0     0   176     0 15161   332    28     0\n    159     0     0    92     1     0  1745  1462     0     0]\n [    0    59     0     3     0    51    61   128   137    76     4     0\n    128     0     0   771   338     0   416  1071     0     0]\n [    0     3     0     0     0     0     0     0  8597     0     0     0\n      0     0     0    30     2     0     4    19     0     0]\n [    0     0     0     5     0    14     4     0  1005  5637     1     0\n     43     0     0   256    29     0  2855    66     0     0]\n [    0     5     1    29     0     0    27     0  5853   254    38     0\n      0     0     0    23     3     0  2083   496     0     0]\n [    0    46     0     8     0     0    11     0  1036   132     5     4\n     20     0     0   559   203     0  4883   256     0     0]\n [    0   148     0    33     0     2     1    33   482     9     0   182\n    751     0     0  4827   387     0  4489  6661     0     0]\n [    0    65     0     0     0  2807     0     0     4   495    45     1\n    150    54     0   979   716     0   348   220     0     0]\n [    0     5     9     1     0     0     0     0   357     0     2     0\n      0     0    25     0     0     0     5   397     0     0]\n [    0     0     0     0     0     0     0     0     6     0     0     0\n      0     0     0  5733    65     0     0     5     0     0]\n [    0     2     0     0     0     0     0     0     0     0     0     0\n      0     0     0   284  2122     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0   921     0     0     0\n      0     0     0    14     0     0  1269   369     0     0]\n [    0     0     0     0     0     0     0     0  2605     0     0     0\n      0     0     0    28    20     0  4066   250     0     0]\n [    0   254     0     0     0     0     0     0   399     0     0     0\n      0     0     0     5     8     0    13  2109     0     0]\n [    0   515     0     0     0     0     0     0     1     0     0     0\n      0     0     0    39   334     0     0   173     0     0]\n [    0    81     0     3     0     0     0     0  2717     0     0     0\n      0     0     0     0     0     0    32   399     0     0]]",
        "each_acc": "[7.20975783e+01 9.53720185e+01 9.50962420e-01 5.59711547e+01\n 2.15118617e+00 2.82900828e+01 9.12768385e-01 3.94696269e+00\n 9.93298671e+01 5.68532526e+01 4.31230141e-01 5.58425241e-02\n 4.17106359e+00 9.17743032e-01 3.12109863e+00 9.86916853e+01\n 8.81229236e+01 0.00000000e+00 5.83440953e+01 7.56456241e+01\n 0.00000000e+00 0.00000000e+00]",
        "aa": 33.88077909049317,
        "kappa": 31.847611525694887
    }
}