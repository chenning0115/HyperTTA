{
    "eval_time": 155.0076904296875,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.2_pc",
            "patch_size": 13,
            "serve_patch_size": 13,
            "batch_size": 15,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "spectral_size": 240,
            "random_rotate": false,
            "noise_type": "thick_fog"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 10,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.2-noPCA_split",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.2-noPCA_split",
        "path_res": "./res/wh_0.2-noPCA_split_test_thick_fog_01091103",
        "path_pic": "./res/wh_0.2-noPCA_split_test_thick_fog_01091103.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000     11232\n           1     0.0286    0.0153    0.0199      2809\n           2     0.0650    0.0005    0.0009     17456\n           3     0.9286    0.0016    0.0032    130628\n           4     0.0000    0.0000    0.0000      4974\n           5     0.0000    0.0000    0.0000     35645\n           6     0.0000    0.0000    0.0000     19282\n           7     0.0000    0.0000    0.0000      3243\n           8     0.0517    0.9618    0.0981      8655\n           9     0.0000    0.0000    0.0000      9915\n          10     0.0000    0.0000    0.0000      8812\n          11     0.0000    0.0000    0.0000      7163\n          12     0.0000    0.0000    0.0000     18005\n          13     0.0000    0.0000    0.0000      5884\n          14     0.0000    0.0000    0.0000       801\n          15     0.1070    0.2145    0.1427      5809\n          16     0.0237    1.0000    0.0462      2408\n          17     0.0000    0.0000    0.0000      2573\n          18     0.0000    0.0000    0.0000      6969\n          19     0.0000    0.0000    0.0000      2788\n          20     0.0000    0.0000    0.0000      1062\n          21     0.0000    0.0000    0.0000      3232\n\n    accuracy                         0.0396    309345\n   macro avg     0.0547    0.0997    0.0141    309345\nweighted avg     0.3997    0.0396    0.0074    309345\n",
        "oa": 3.9557775299422975,
        "confusion": "[[     0    476      4      0      0      0      0      0    175      0\n       0      0      0      0      0      0  10577      0      0      0\n       0      0]\n [     0     43      0      0      0      0      0      0     17      0\n       0      0      0      0      0      0   2749      0      0      0\n       0      0]\n [     0    496      8      0      0      0      0      0    217      0\n       0      0      0      0      0      0  16735      0      0      0\n       0      0]\n [ 25040    156    111    208      0      0      0      0 103323      0\n       0      0      0      0      0      0   1778      0     12      0\n       0      0]\n [     0    333      0      0      0      0      0      0   2127      0\n       0      0      0      0      0      0   2514      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0   3161      0\n       0      0      0      0      0   7409  19920      0   5155      0\n       0      0]\n [     0      0      0      0      0      0      0      0  14213      0\n       0      0      0      0      0      0   5069      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0     10      0\n       0      0      0      0      0      0   3233      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0   8324      0\n       0      0      0      0      0      3    328      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0   5641      0\n       0      0      0      0      0    465   3809      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0   5316      0\n       0      0      0      0      0      0   3496      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0   2894      0\n       0      0      0      0      0      0   4269      0      0      0\n       0      0]\n [     0      2      0     16      0      0      0      0   1668      0\n       0      0      0      0      0   2460  11276      0    858   1725\n       0      0]\n [     0      0      0      0      0      0      0      0    445     56\n       0      0      0      0      0     45   5272      0     66      0\n       0      0]\n [     0      0      0      0      0      0      0      0    724      0\n       0      0      0      0      0      0     77      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      0      0\n       0      0      0      0      0   1246   4563      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      0      0\n       0      0      0      0      0      0   2408      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0   2384      0\n       0      0      0      0      0     22    126      0     41      0\n       0      0]\n [     0      0      0      0      0      0      0      0   6129      0\n       0      0      0      0      0      0    840      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0   1161      0\n       0      0      0      0      0      0   1627      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      0      0\n       0      0      0      0      0      0   1062      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0   3165      0\n       0      0      0      0      0      0     67      0      0      0\n       0      0]]",
        "each_acc": "[0.00000000e+00 1.53079388e+00 4.58295142e-02 1.59230793e-01\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 9.61756210e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.14494750e+01\n 1.00000000e+02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00]",
        "aa": 9.970952280217467,
        "kappa": 1.8301233323182342
    }
}