{
    "eval_time": 91.71923756599426,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.2_pc",
            "patch_size": 13,
            "serve_patch_size": 13,
            "batch_size": 15,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "spectral_size": 270,
            "random_rotate": false,
            "noise_type": "thick_fog"
        },
        "net": {
            "trainer": "CNN",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 100,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.2-CNN_split",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.2-CNN_split",
        "path_res": "./res/wh_0.2-CNN_split_test_thick_fog_01091429",
        "path_pic": "./res/wh_0.2-CNN_split_test_thick_fog_01091429.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.0547    0.0191    0.0284     11232\n           1     0.0249    0.0210    0.0228      2809\n           2     0.3846    0.0017    0.0034     17456\n           3     0.9948    0.0538    0.1022    130628\n           4     0.0000    0.0000    0.0000      4974\n           5     0.0000    0.0000    0.0000     35645\n           6     0.0000    0.0000    0.0000     19282\n           7     0.0000    0.0000    0.0000      3243\n           8     0.0467    0.9867    0.0891      8655\n           9     0.0000    0.0000    0.0000      9915\n          10     0.0000    0.0000    0.0000      8812\n          11     0.0000    0.0000    0.0000      7163\n          12     0.0000    0.0000    0.0000     18005\n          13     0.0000    0.0000    0.0000      5884\n          14     0.0000    0.0000    0.0000       801\n          15     0.0621    0.3918    0.1072      5809\n          16     0.0467    0.9697    0.0892      2408\n          17     0.0000    0.0000    0.0000      2573\n          18     0.0055    0.0176    0.0084      6969\n          19     0.0000    0.0000    0.0000      2788\n          20     0.0000    0.0000    0.0000      1062\n          21     0.0000    0.0000    0.0000      3232\n\n    accuracy                         0.0666    309345\n   macro avg     0.0736    0.1119    0.0205    309345\nweighted avg     0.4469    0.0666    0.0500    309345\n",
        "oa": 6.66311076629653,
        "confusion": "[[   215   1457      1      0      0      0      0      0     31     65\n       0      0      0      0      0     48   9211      0    200      0\n       0      4]\n [     0     59      0      0      0      0      0      0      4      0\n       0      0      0      0      0      1   2739      0      6      0\n       0      0]\n [     0    573     30      0      0      0      0      0    376      0\n       0      0      0      0      0    139  16286      0     52      0\n       0      0]\n [  3256    155     27   7034      0      0      0      0 105220      0\n       0      0      0      0      0    265    529      0  11943      0\n       0   2199]\n [   453     93      7      8      0      0      0      0    496      0\n       0      0      0      0      0      6   2919      0    979      0\n       0     13]\n [     0      0      0      0      0      0      0      0  10063      0\n       0      0      0      0      0  17633   1820      0   6129      0\n       0      0]\n [     0      8      0     29      0      0      0      0  16697      0\n       0      0      0      0      0   2285    151      0     39      0\n       0     73]\n [     0      0      0      0      0      0      0      0     49      0\n       0      0      0      0      0   1506   1688      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0   8540      0\n       0      0      0      0      0     98      1      0      0      0\n       0     16]\n [     0      0      0      0      0      0      0      0   8026      0\n       0      0      0      0      0   1857     18      0     14      0\n       0      0]\n [     0      9      0      0      0      0      0      0   5871      0\n       0      0      0      0      0   2433    276      0    219      0\n       0      4]\n [     7      0      0      0      0      0      0      0   4194      0\n       0      0      0      0      0   2257    610      0     57      0\n       0     38]\n [     0      0      0      0      0      0      0      0   7708      0\n       0      0      0      0      0   4250   4276      0   1771      0\n       0      0]\n [     0     11     13      0      0   1044      0      0   1971    360\n       0      0      0      0      0    841   1074      0    570      0\n       0      0]\n [     0      0      0      0      0      0      0      0    535      0\n       0      0      0      0      0     59     40      0    167      0\n       0      0]\n [     0      0      0      0      0      0      0      0     35      0\n       0      0      0      0      0   2276   3498      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0     13      0\n       0      0      0      0      0     60   2335      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0   2380      0\n       0      0      0      0      0      6      0      0    187      0\n       0      0]\n [     0      0      0      0      0      0      0      0   6321      0\n       0      0      0      0      0    519      6      0    123      0\n       0      0]\n [     0      0      0      0      0      0      0      0   1272      0\n       0      0      0      0      0     87   1429      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      0      0\n       0      0      0      0      0      0   1062      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0   3196      0\n       0      0      0      0      0     14      0      0     22      0\n       0      0]]",
        "each_acc": "[ 1.91417379  2.1003916   0.17186068  5.38475671  0.          0.\n  0.          0.         98.67128827  0.          0.          0.\n  0.          0.          0.         39.18058186 96.96843854  0.\n  1.7649591   0.          0.          0.        ]",
        "aa": 11.188929570492432,
        "kappa": 3.5398100589357995
    }
}