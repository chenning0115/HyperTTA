{
    "train_oa": {
        "type": "index_value",
        "index": [
            1,
            2
        ],
        "value": [
            27.824597132651245,
            32.96966170456933
        ]
    },
    "train_aa": {
        "type": "index_value",
        "index": [
            1,
            2
        ],
        "value": [
            5.427425128753001,
            5.030738449130772
        ]
    },
    "train_kappa": {
        "type": "index_value",
        "index": [
            1,
            2
        ],
        "value": [
            -0.11686294390726992,
            -1.0239089307576776
        ]
    },
    "eval_time": 311.0949912071228,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.2_pc",
            "patch_size": 13,
            "serve_patch_size": 13,
            "batch_size": 15,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "spectral_size": 270,
            "random_rotate": false,
            "noise_type": "thick_fog"
        },
        "net": {
            "trainer": "CNN",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 100,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.2-CNN_split",
        "train_sign": "tent",
        "path_model_save": "./save_models/wh_0.2-CNN_split",
        "path_res": "./res/wh_0.2-CNN_split_tent_thick_fog_01091456",
        "path_pic": "./res/wh_0.2-CNN_split_tent_thick_fog_01091456.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.0493    0.0726    0.0588     11232\n           1     0.0548    0.0288    0.0378      2809\n           2     0.1198    0.0475    0.0680     17456\n           3     0.4063    0.7427    0.5252    130628\n           4     0.0163    0.0145    0.0153      4974\n           5     0.1164    0.0198    0.0339     35645\n           6     0.0782    0.0348    0.0482     19282\n           7     0.0074    0.0040    0.0052      3243\n           8     0.0360    0.0023    0.0043      8655\n           9     0.0547    0.0065    0.0115      9915\n          10     0.0389    0.0093    0.0150      8812\n          11     0.0129    0.0027    0.0044      7163\n          12     0.1214    0.0740    0.0919     18005\n          13     0.0257    0.0025    0.0046      5884\n          14     0.0054    0.0012    0.0020       801\n          15     0.5596    0.0105    0.0206      5809\n          16     0.0000    0.0000    0.0000      2408\n          17     0.0216    0.0031    0.0054      2573\n          18     0.0441    0.0222    0.0296      6969\n          19     0.0054    0.0036    0.0043      2788\n          20     0.0000    0.0000    0.0000      1062\n          21     0.0083    0.0040    0.0054      3232\n\n    accuracy                         0.3297    309345\n   macro avg     0.0810    0.0503    0.0451    309345\nweighted avg     0.2228    0.3297    0.2430    309345\n",
        "oa": 32.96966170456933,
        "confusion": "[[  816    55   265  8586   127   126   223    36     6    60   112    30\n    472    23    38     0     5    25   138    67     5    17]\n [  138    81   303  1781    31    13    62    13    26     6    26    13\n     83     6     5     1     0     3   141    66     3     8]\n [  639    74   829 14442   170   144   380    44    11    53    60    66\n    262    14    11     0     4    32   171    13     4    33]\n [ 7082   843  3057 97022  2194  2946  4643   777   301   401  1186   879\n   4356   316    40    33    58   122  1662  1386   127  1197]\n [  392    34   166  3456    72    63   163    42     5    23    41    29\n    278    20     6     1     3     4    99    45    12    20]\n [ 1841    69   292 28652   523   706   759   219    31   167   138   123\n   1458    70    12     3     8    39   369    97    12    57]\n [  855    38   160 15845   183   374   671   104    19    94    85    55\n    466    23     5     0     3    35   137    52     2    76]\n [  179     6    58  2610   105    35    41    13     3    11    23     7\n    117     2     2     0     1     1    20     4     4     1]\n [  429    11    36  7214   107   154   220    16    20    46    45    28\n    134     4     3     4     1    12   142    16     0    13]\n [  490    18    66  8011    75   304   159    88    14    64    41    40\n    463     9     3     1     0     7    42    16     0     4]\n [  380     9    49  7372    77   150   209    33    14    48    82    18\n    215     8     9     0     2    18    82    17     0    20]\n [  348     9    36  6035    77    70    93    40     3    26    25    19\n    298    12     4     0     0     2    44     6     1    15]\n [ 1121    58   853 13057   211   398   323   151    12    41   100    91\n   1332    36    20     2     2    26   110    11    11    39]\n [  245    16    58  4905    59    81    96    56     0    28    17    19\n    245    15     1     0     0    10    16     0     2    15]\n [   57     1     2   683     7    16     8     4     1     0     2     0\n      7     2     1     0     0     1     7     2     0     0]\n [  475    47   293  4101   118   168    67    26    63    27    32    11\n    183     6     8    61    14     2    80    10     2    15]\n [  149     9   148  1639    74    56    23    44     4     6    16     4\n    193    11     9     0     0     4    14     0     0     5]\n [   81     0    13  2316    32    19    23     4     1     9     5     3\n     48     0     2     0     0     8     6     1     0     2]\n [  350    36    34  5830    63    73   170    10     9    31    32    15\n    128     4     2     2     1     2   155    14     1     7]\n [  181    13    65  2175    31    79    78    11     6    13    11     7\n     73     0     2     1     0     3    18    10     1    10]\n [  193    40    92   522    35    10    32     9     0     5    15    13\n     75     0     1     0     0     5    12     0     0     3]\n [  102    10    46  2566    45    82   140    13     6    11    15     8\n     85     3     1     0     1    10    46    29     0    13]]",
        "each_acc": "[ 7.26495726  2.88358847  4.74908341 74.27350951  1.44752714  1.98064245\n  3.47992947  0.4008634   0.2310803   0.64548664  0.93054925  0.26525199\n  7.39794502  0.25492862  0.12484395  1.05009468  0.          0.3109211\n  2.22413546  0.35868006  0.          0.40222772]",
        "aa": 5.030738449130772,
        "kappa": -1.0239089307576776
    }
}