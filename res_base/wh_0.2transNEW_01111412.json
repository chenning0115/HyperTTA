{
    "epoch_loss": {
        "type": "index_value",
        "index": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            16,
            17,
            18,
            19,
            20,
            21,
            22,
            23,
            24,
            25,
            26,
            27,
            28,
            29,
            30,
            31,
            32,
            33,
            34,
            35,
            36,
            37,
            38,
            39,
            40,
            41,
            42,
            43,
            44,
            45,
            46,
            47,
            48,
            49,
            50
        ],
        "value": [
            0.3409780722063108,
            0.10820225027008905,
            0.07194542466535819,
            0.057487722992624994,
            0.04700091006564564,
            0.04016231774319524,
            0.037132841022828454,
            0.030689009969184198,
            0.03027174699748187,
            0.029139805785152195,
            0.025387264047713638,
            0.02277950246459172,
            0.02437283377996002,
            0.02210446457836377,
            0.020990931569211984,
            0.019263914525297448,
            0.020989256444302905,
            0.01749064252393516,
            0.01824266587753548,
            0.016700810002303258,
            0.015526810285269109,
            0.015798955158517754,
            0.014182893359589482,
            0.014776508585454802,
            0.014676254163836744,
            0.0148204643933288,
            0.014459507628557564,
            0.012422135889769086,
            0.01363146745196847,
            0.013098339853566404,
            0.013294205289984266,
            0.011347126858029308,
            0.010484849649848827,
            0.01177470172630242,
            0.012411601077618958,
            0.011127618778276477,
            0.010548906035325097,
            0.011530758125086846,
            0.008864710056018394,
            0.010957774211163505,
            0.00887977725239932,
            0.008702584040298366,
            0.010508851123550482,
            0.009193024220661575,
            0.009917055876904158,
            0.008519676957249865,
            0.008537516076028841,
            0.008917620308548322,
            0.008118509425592122,
            0.009456619775481557
        ]
    },
    "train_oa": {
        "type": "index_value",
        "index": [
            10,
            20,
            30,
            40,
            50
        ],
        "value": [
            99.59301103945432,
            99.71552797038905,
            99.71940713442919,
            99.83772163765376,
            99.76692689392102
        ]
    },
    "train_aa": {
        "type": "index_value",
        "index": [
            10,
            20,
            30,
            40,
            50
        ],
        "value": [
            98.99838432741956,
            99.13927207805784,
            99.15897806041887,
            99.44120383442076,
            99.48737165588764
        ]
    },
    "train_kappa": {
        "type": "index_value",
        "index": [
            10,
            20,
            30,
            40,
            50
        ],
        "value": [
            99.48572411338603,
            99.64058177006105,
            99.64545279086647,
            99.79495734794088,
            99.70550126328567
        ]
    },
    "max_oa": {
        "type": "index_value",
        "index": [
            10,
            20,
            30,
            40,
            50
        ],
        "value": [
            99.59301103945432,
            99.71552797038905,
            99.71940713442919,
            99.83772163765376,
            99.83772163765376
        ]
    },
    "eval_time": 181.8032684326172,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.2_pc",
            "patch_size": 21,
            "serve_patch_size": 21,
            "batch_size": 32,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "append_dim": false,
            "spectral_size": 270,
            "random_rotate": true,
            "noise_type": "clean"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 50,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.2transNEW",
        "train_sign": "train",
        "path_model_save": "./save_models/wh_0.2transNEW",
        "path_res": "./res_base/wh_0.2transNEW_01111412",
        "path_pic": "./res_base/wh_0.2transNEW_01111412.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.9978    0.9992    0.9985     11232\n           1     0.9917    0.9769    0.9842      2809\n           2     0.9972    0.9959    0.9966     17456\n           3     0.9996    1.0000    0.9998    130628\n           4     0.9988    0.9994    0.9991      4974\n           5     0.9989    1.0000    0.9995     35645\n           6     0.9981    0.9915    0.9948     19282\n           7     0.9985    0.9985    0.9985      3243\n           8     0.9994    0.9983    0.9988      8655\n           9     0.9990    0.9943    0.9966      9915\n          10     0.9977    0.9993    0.9985      8812\n          11     0.9921    0.9999    0.9960      7163\n          12     0.9974    0.9879    0.9926     18005\n          13     0.9924    0.9976    0.9950      5884\n          14     0.9961    0.9638    0.9797       801\n          15     0.9998    0.9991    0.9995      5809\n          16     0.9996    0.9996    0.9996      2408\n          17     0.9222    0.9992    0.9591      2573\n          18     0.9981    0.9973    0.9977      6969\n          19     0.9872    0.9978    0.9925      2788\n          20     1.0000    1.0000    1.0000      1062\n          21     0.9975    0.9981    0.9978      3232\n\n    accuracy                         0.9977    309345\n   macro avg     0.9936    0.9952    0.9943    309345\nweighted avg     0.9978    0.9977    0.9977    309345\n",
        "oa": 99.77339216732128,
        "confusion": "[[ 11223      8      0      1      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [    24   2744     41      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [     1     15  17385     46      0      3      0      0      1      0\n       0      1      0      4      0      0      0      0      0      0\n       0      0]\n [     0      0      0 130622      6      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [     0      0      0      3   4971      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [     0      0      0      0      0  35645      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [     0      0      0      3      0      0  19119      5      0      0\n       7     51     36     11      1      0      0      1     10     35\n       0      3]\n [     0      0      0      0      0      0      0   3238      0      0\n       0      0      1      0      0      0      0      4      0      0\n       0      0]\n [     0      0      3      0      0      0      1      0   8640      4\n       0      0      0      0      0      0      0      0      2      0\n       0      5]\n [     0      0      0      1      0      0      0      0      0   9858\n       0      0      2     30      0      0      0     23      1      0\n       0      0]\n [     0      0      1      0      0      0      2      0      0      0\n    8806      0      0      0      2      0      0      0      0      1\n       0      0]\n [     0      0      0      0      0      0      1      0      0      0\n       0   7162      0      0      0      0      0      0      0      0\n       0      0]\n [     0      0      0      1      0     24      0      0      0      0\n       0      4  17787      0      0      0      0    189      0      0\n       0      0]\n [     0      0      3      0      0      1      2      0      0      4\n       0      1      3   5870      0      0      0      0      0      0\n       0      0]\n [     0      0      0      0      0      0     25      0      0      0\n       4      0      0      0    772      0      0      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      4      0\n       0      0      0      0      0   5804      1      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      0      0\n       0      0      0      0      0      1   2407      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      0      2\n       0      0      0      0      0      0      0   2571      0      0\n       0      0]\n [     0      0      0      0      0     11      0      0      0      0\n       3      0      5      0      0      0      0      0   6950      0\n       0      0]\n [     0      0      0      0      0      0      0      0      0      0\n       6      0      0      0      0      0      0      0      0   2782\n       0      0]\n [     0      0      0      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n    1062      0]\n [     0      0      0      0      0      0      6      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0   3226]]",
        "each_acc": "[ 99.91987179  97.68600926  99.59326306  99.9954068   99.93968637\n 100.          99.15465201  99.84582177  99.82668977  99.42511346\n  99.93191103  99.98603937  98.78922522  99.76206662  96.37952559\n  99.91392667  99.95847176  99.92226972  99.72736404  99.78479197\n 100.          99.81435644]",
        "aa": 99.51620285104023,
        "kappa": 99.71367499741463
    }
}