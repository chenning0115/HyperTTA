{
    "eval_time": 202.3070366382599,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.2_pc",
            "patch_size": 21,
            "serve_patch_size": 21,
            "batch_size": 32,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "append_dim": false,
            "spectral_size": 270,
            "random_rotate": true,
            "noise_type": "kernal"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 50,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.2transNEW",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.2transNEW",
        "path_res": "./res_base/wh_0.2transNEW_test_kernal_01111612",
        "path_pic": "./res_base/wh_0.2transNEW_test_kernal_01111612.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     1.0000    0.0449    0.0859     11232\n           1     0.0612    0.0477    0.0536      2809\n           2     0.0731    0.9989    0.1362     17456\n           3     1.0000    0.0003    0.0006    130628\n           4     0.0000    0.0000    0.0000      4974\n           5     0.0000    0.0000    0.0000     35645\n           6     0.0000    0.0000    0.0000     19282\n           7     0.0000    0.0000    0.0000      3243\n           8     1.0000    0.3957    0.5671      8655\n           9     0.0000    0.0000    0.0000      9915\n          10     0.0000    0.0000    0.0000      8812\n          11     0.8110    0.0515    0.0969      7163\n          12     0.4440    0.0740    0.1268     18005\n          13     0.0000    0.0000    0.0000      5884\n          14     0.0000    0.0000    0.0000       801\n          15     0.0000    0.0000    0.0000      5809\n          16     0.0422    1.0000    0.0810      2408\n          17     0.0000    0.0000    0.0000      2573\n          18     0.6036    0.2668    0.3700      6969\n          19     0.0000    0.0000    0.0000      2788\n          20     0.0000    0.0000    0.0000      1062\n          21     0.0000    0.0000    0.0000      3232\n\n    accuracy                         0.0889    309345\n   macro avg     0.2289    0.1309    0.0690    309345\nweighted avg     0.5498    0.0889    0.0460    309345\n",
        "oa": 8.89169050736233,
        "confusion": "[[   504    741   5272      0      0      0      0      0      0      0\n       0      0      0      0      0      0   4715      0      0      0\n       0      0]\n [     0    134   2051      0      0      0      0      0      0      0\n       0      0      0      0      0      0    624      0      0      0\n       0      0]\n [     0     14  17437      0      0      0      0      0      0      0\n       0      0      0      0      0      0      5      0      0      0\n       0      0]\n [     0      0 130590     38      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [     0      0   4974      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [     0      0   3569      0      0      0      0      0      0      0\n       0      0    501      0      0      0  31575      0      0      0\n       0      0]\n [     0      5  19047      0      0      0      0      0      0      0\n       0      0    154      0      0      0     76      0      0      0\n       0      0]\n [     0      0   2364      0      0      0      0      0      0      0\n       0      0    201      0      0      0    678      0      0      0\n       0      0]\n [     0     77   2925      0      0      0      0      0   3425      0\n       0      0      0      0      0      0    501      0   1069    658\n       0      0]\n [     0    399   4377      0      0      0     30      0      0      0\n       0     84    319      0      0      0   4705      0      0      1\n       0      0]\n [     0      9   8495      0      0      0      0      0      0      0\n       0      0      0      0      0      0      1      0    152    155\n       0      0]\n [     0     44   5292      0      0      0      0      0      0      0\n       0    369    167      0      0      0   1290      0      0      1\n       0      0]\n [     0     96  14447      0      0      0      0      0      0      0\n       0      2   1332      0      0      0   2128      0      0      0\n       0      0]\n [     0      0   3094      0      0      0      0      0      0      0\n       0      0    254      0      0      0   2536      0      0      0\n       0      0]\n [     0      0    801      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [     0    185      0      0      0      0      0      0      0      0\n       0      0      0      0      0      0   5624      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      0      0\n       0      0      0      0      0      0   2408      0      0      0\n       0      0]\n [     0      0   2467      0      0      0      0      0      0      0\n       0      0     63      0      0      0     43      0      0      0\n       0      0]\n [     0    485   4415      0      0      0      0      0      0      0\n       0      0      9      0      0      0    127      0   1859     74\n       0      0]\n [     0      0   2754      0      0      0      0      0      0      0\n       0      0      0      0      0      0     34      0      0      0\n       0      0]\n [     0      0   1062      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [     0      0   3203      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0     29\n       0      0]]",
        "each_acc": "[4.48717949e+00 4.77038092e+00 9.98911549e+01 2.90902410e-02\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 3.95725014e+01 0.00000000e+00 0.00000000e+00 5.15147285e+00\n 7.39794502e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 1.00000000e+02 0.00000000e+00 2.66752762e+01 0.00000000e+00\n 0.00000000e+00 0.00000000e+00]",
        "aa": 13.089772776353456,
        "kappa": 4.467852527863869
    }
}