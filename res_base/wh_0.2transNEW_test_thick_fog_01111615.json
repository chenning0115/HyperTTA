{
    "eval_time": 170.93402552604675,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.2_pc",
            "patch_size": 21,
            "serve_patch_size": 21,
            "batch_size": 32,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "append_dim": false,
            "spectral_size": 270,
            "random_rotate": true,
            "noise_type": "thick_fog"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 50,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.2transNEW",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.2transNEW",
        "path_res": "./res_base/wh_0.2transNEW_test_thick_fog_01111615",
        "path_pic": "./res_base/wh_0.2transNEW_test_thick_fog_01111615.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000     11232\n           1     0.0164    0.0616    0.0259      2809\n           2     0.0000    0.0000    0.0000     17456\n           3     0.9919    0.0019    0.0037    130628\n           4     0.0000    0.0000    0.0000      4974\n           5     0.0000    0.0000    0.0000     35645\n           6     0.0000    0.0000    0.0000     19282\n           7     0.0000    0.0000    0.0000      3243\n           8     0.1225    0.6982    0.2084      8655\n           9     0.0000    0.0000    0.0000      9915\n          10     0.0000    0.0000    0.0000      8812\n          11     0.0000    0.0000    0.0000      7163\n          12     1.0000    0.0039    0.0077     18005\n          13     0.0000    0.0000    0.0000      5884\n          14     0.0000    0.0000    0.0000       801\n          15     0.1325    0.0489    0.0714      5809\n          16     0.0147    1.0000    0.0290      2408\n          17     0.0000    0.0000    0.0000      2573\n          18     0.0000    0.0000    0.0000      6969\n          19     0.0000    0.0000    0.0000      2788\n          20     0.0000    0.0000    0.0000      1062\n          21     0.0000    0.0000    0.0000      3232\n\n    accuracy                         0.0298    309345\n   macro avg     0.1035    0.0825    0.0157    309345\nweighted avg     0.4832    0.0298    0.0097    309345\n",
        "oa": 2.9811375648547735,
        "confusion": "[[    0  1560     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0  9672     0     0     0     0     0]\n [    0   173     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0  2636     0     0     0     0     0]\n [    0  1493     0     0     0     0     0     0    29     0     0     0\n      0     0     0     0 15934     0     0     0     0     0]\n [80414  4067    49   244     0     0     0     0 28561     0     0     0\n      0     0     0    28 16967     0   298     0     0     0]\n [  923     0     0     0     0     0     0     0   870     0     0     0\n      0     0     0     0  3176     0     5     0     0     0]\n [   83     0     0     0     0     0     0     0    76     0     0     0\n      0     0     0    15 35446     0    25     0     0     0]\n [    0   659     8     0     0     0     0     0  4868     0     0     0\n      0     0     0    26 13721     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0  3243     0     0     0     0     0]\n [    0   243     2     0     0     0     0     0  6043     0     0     0\n      0     0     0     6  2361     0     0     0     0     0]\n [   26   569     0     0     0     0     0     0   437     0     0     0\n      0     0     0   158  8725     0     0     0     0     0]\n [    2   458     8     0     0     0     0     0  3045     0     0     0\n      0     0     0     3  5296     0     0     0     0     0]\n [    0   520     0     0     0     0     0     0   941     0     0     0\n      0     0     0     3  5699     0     0     0     0     0]\n [  656   250     0     2     0    30     0     4   187     0     1     0\n     70     0     0  1605 15173     7     6    14     0     0]\n [    0   142     0     0     0     0     0     0     0     0     0     0\n      0     0     0     3  5739     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0   801     0     0     0     0     0]\n [    0   143     0     0     0     0     0     0     0     0     0     0\n      0     0     0   284  5382     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0  2408     0     0     0     0     0]\n [  753     0     0     0     0     0     0     0   685     0     0     0\n      0     0     0     1  1134     0     0     0     0     0]\n [    0   264     0     0     0     0     0     0  2349     0     0     0\n      0     0     0    11  4345     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0  1156     0     0     0\n      0     0     0     0  1632     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0  1062     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0    99     0     0     0\n      0     0     0     0  3133     0     0     0     0     0]]",
        "each_acc": "[  0.           6.15877536   0.           0.18678997   0.\n   0.           0.           0.          69.82091277   0.\n   0.           0.           0.38878089   0.           0.\n   4.8889654  100.           0.           0.           0.\n   0.           0.        ]",
        "aa": 8.247464745148218,
        "kappa": 1.08753746598389
    }
}