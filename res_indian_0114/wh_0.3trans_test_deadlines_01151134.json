{
    "eval_time": 154.2168207168579,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.3_pc",
            "patch_size": 21,
            "serve_patch_size": 21,
            "batch_size": 32,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "append_dim": false,
            "spectral_size": 270,
            "random_rotate": true,
            "noise_type": "deadlines"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 60,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.3trans",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.3trans",
        "path_res": "./res_indian_0114/wh_0.3trans_test_deadlines_01151134",
        "path_pic": "./res_indian_0114/wh_0.3trans_test_deadlines_01151134.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.9980    0.7095    0.8294      9828\n           1     0.7426    0.6513    0.6940      2458\n           2     0.6487    0.9690    0.7772     15274\n           3     0.9822    0.9664    0.9742    114299\n           4     1.0000    0.0473    0.0904      4352\n           5     0.9967    0.2216    0.3626     31189\n           6     0.5133    0.7326    0.6037     16872\n           7     0.3257    0.4455    0.3763      2837\n           8     0.9987    0.8797    0.9354      7573\n           9     0.9960    0.2289    0.3723      8675\n          10     0.4692    0.1520    0.2296      7710\n          11     0.5192    0.0215    0.0414      6267\n          12     0.2470    0.9907    0.3954     15754\n          13     0.8325    0.6003    0.6976      5149\n          14     0.9414    0.6419    0.7634       701\n          15     0.9985    0.9333    0.9648      5083\n          16     0.9589    0.9962    0.9772      2107\n          17     0.0000    0.0000    0.0000      2251\n          18     0.9854    0.4413    0.6096      6098\n          19     0.3859    0.2988    0.3368      2440\n          20     0.0203    0.0172    0.0186       929\n          21     0.0000    0.0000    0.0000      2828\n\n    accuracy                         0.7166    270674\n   macro avg     0.6618    0.4975    0.5023    270674\nweighted avg     0.8306    0.7166    0.7029    270674\n",
        "oa": 71.65667925253257,
        "confusion": "[[  6973    530   1748    199      0      0      0      0      0      0\n       0      0    309      0      0      0      0      0      0     69\n       0      0]\n [    14   1601    801      1      0      0      2      5      0      0\n       0     26      7      0      0      0      0      0      0      1\n       0      0]\n [     0      1  14801      0      0      0      0      7      0      0\n       0      0    452      7      0      0      0      0      0      0\n       6      0]\n [     0      0   2148 110454      0      0    854      1      0      0\n       0      0    830      0     11      0      0      0      0      1\n       0      0]\n [     0     11   2196   1435    206      0      2     12      0      0\n      24      4    331      0      0      0      0      0      4      4\n     123      0]\n [     0      0      4      0      0   6913     50    767      0      0\n       2      9  23002    245      0      0      0      0     10     16\n     171      0]\n [     0      0     16      0      0      0  12361    249      0      0\n       5     10   4227      0      0      0      0      0      0      4\n       0      0]\n [     0      0    137      0      0      0    208   1264      0      0\n       0      0   1228      0      0      0      0      0      0      0\n       0      0]\n [     0      3     46     10      0      0    329      1   6662      0\n      72      0     81      0      0      2      0      0      4    361\n       2      0]\n [     0      0      1     69      0      6   2368    925      4   1986\n    1146      0   1794    367      0      0      0      0      9      0\n       0      0]\n [     0      0    227    137      0      0   3366    116      0      0\n    1172      0   1958      0     16      0      0      0      4    266\n     448      0]\n [     0      0      0      0      0      0    103     14      0      1\n       1    135   6009      0      0      2      0      0      1      0\n       1      0]\n [     0      0     42      3      0      0      8     93      0      0\n       0      0  15608      0      0      0      0      0      0      0\n       0      0]\n [     0      0     43      0      0     17     12     18      0      0\n       0      8   1960   3091      0      0      0      0      0      0\n       0      0]\n [     0      1     47     37      0      0    147      3      0      0\n       0      0     12      0    450      0      0      0      0      4\n       0      0]\n [     0      7     23      0      0      0      2    121      4      7\n       0     57     17      3      1   4744     90      0      7      0\n       0      0]\n [     0      0      2      0      0      0      0      0      0      0\n       0      2      1      0      0      3   2099      0      0      0\n       0      0]\n [     0      0      0      0      0      0    885      0      0      0\n       0      0   1366      0      0      0      0      0      0      0\n       0      0]\n [     0      2     51     27      0      0    634     45      1      0\n      76      9   2108      0      0      0      0      0   2691    433\n      21      0]\n [     0      0    407      6      0      0     26     62      0      0\n       0      0   1207      0      0      0      0      0      1    729\n       2      0]\n [     0      0     47      0      0      0      0    178      0      0\n       0      0    688      0      0      0      0      0      0      0\n      16      0]\n [     0      0     28     72      0      0   2725      0      0      0\n       0      0      2      0      0      0      0      0      0      1\n       0      0]]",
        "each_acc": "[70.95034595 65.13425549 96.90323425 96.63601606  4.73345588 22.16486582\n 73.26339497 44.55410645 87.97042123 22.89337176 15.20103761  2.15414074\n 99.07325124 60.03107399 64.19400856 93.33071021 99.62031324  0.\n 44.1292227  29.87704918  1.72228202  0.        ]",
        "aa": 49.75166169867231,
        "kappa": 64.32031705687116
    }
}