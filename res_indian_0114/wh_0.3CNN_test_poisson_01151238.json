{
    "eval_time": 95.39076828956604,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.3_pc",
            "patch_size": 21,
            "serve_patch_size": 21,
            "batch_size": 32,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "append_dim": false,
            "spectral_size": 270,
            "random_rotate": true,
            "noise_type": "poisson"
        },
        "net": {
            "trainer": "CNN",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 60,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.3CNN",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.3CNN",
        "path_res": "./res_indian_0114/wh_0.3CNN_test_poisson_01151238",
        "path_pic": "./res_indian_0114/wh_0.3CNN_test_poisson_01151238.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     1.0000    0.2414    0.3889      9828\n           1     0.1347    0.9858    0.2371      2458\n           2     0.1298    0.7990    0.2233     15274\n           3     0.9601    0.3829    0.5474    114299\n           4     0.0000    0.0000    0.0000      4352\n           5     0.0000    0.0000    0.0000     31189\n           6     0.6499    0.7054    0.6765     16872\n           7     0.2597    0.0211    0.0391      2837\n           8     0.9936    0.9432    0.9678      7573\n           9     1.0000    0.0001    0.0002      8675\n          10     0.0000    0.0000    0.0000      7710\n          11     0.0000    0.0000    0.0000      6267\n          12     0.1294    0.5010    0.2057     15754\n          13     0.2620    0.2548    0.2584      5149\n          14     1.0000    0.1427    0.2497       701\n          15     0.9980    0.6909    0.8166      5083\n          16     0.6210    0.7527    0.6805      2107\n          17     0.0000    0.0000    0.0000      2251\n          18     1.0000    0.0021    0.0043      6098\n          19     0.0855    0.4385    0.1431      2440\n          20     0.1200    0.0032    0.0063       929\n          21     0.0000    0.0000    0.0000      2828\n\n    accuracy                         0.3523    270674\n   macro avg     0.4247    0.3120    0.2475    270674\nweighted avg     0.6158    0.3523    0.3693    270674\n",
        "oa": 35.22909477822029,
        "confusion": "[[ 2372   958  6373     1     0     0     0     0     0     0     0     0\n    120     0     0     0     4     0     0     0     0     0]\n [    0  2423    35     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0]\n [    0  3048 12204     0     0     0     0     0     0     0     0     0\n      0    22     0     0     0     0     0     0     0     0]\n [    0    69 70283 43763     0     0    18     0     0     0     0     0\n      2    81     0     0     0     0     0    83     0     0]\n [    0  1059  3241    13     0     0     0     0     0     0     0     0\n     24    15     0     0     0     0     0     0     0     0]\n [    0   217     8     1     0     0    41     0     0     0     0     0\n  29176  1734     0     0     0     0     0    12     0     0]\n [    0   133    70    62     0     0 11902   159     0     0     0     0\n   3927     6     0     0     0     0     0   613     0     0]\n [    0   685   130     0     0     0  1411    60     0     0     0    27\n     80   444     0     0     0     0     0     0     0     0]\n [    0    92    33     0     0     0    55     0  7143     0     0     0\n     29     0     0     7     0     0     0   214     0     0]\n [    0    12     0     2     0     0  2292     0     0     1     0     0\n   6366     2     0     0     0     0     0     0     0     0]\n [    0   137   180    91     0     0  1022     0     6     0     0     0\n   1823     1     0     0     0     0     0  4447     3     0]\n [    0   547     0     0     0     0   416     0     0     0     0     0\n   5282     0     0     0     0     0     0    22     0     0]\n [    0  4773  1120     0     0     0   248     0     0     0     0   224\n   7892  1366     0     0     0     0     0   112    19     0]\n [    0   247     3     0     0     0    23     0     0     0     0     0\n   3564  1312     0     0     0     0     0     0     0     0]\n [    0     1    83    13     0     0    59     0     1     0     0     0\n      0     0   100     0     0     0     0   444     0     0]\n [    0   601     0     0     0     0     0     0     0     0     0     0\n      0     6     0  3512   964     0     0     0     0     0]\n [    0   503     0     0     0     0     0     0     0     0     0     0\n      0    18     0     0  1586     0     0     0     0     0]\n [    0     0     1     0     0     0   338     0     0     0     0    17\n   1526     0     0     0     0     0     0   369     0     0]\n [    0   249     1     0     0     0    17     0    39     0     0     0\n   1158     0     0     0     0     0    13  4621     0     0]\n [    0  1367     0     0     0     0     3     0     0     0     0     0\n      0     0     0     0     0     0     0  1070     0     0]\n [    0   863    63     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     3     0]\n [    0     0   201  1637     0     0   468    12     0     0     0     0\n      0     0     0     0     0     0     0   510     0     0]]",
        "each_acc": "[2.41351241e+01 9.85760781e+01 7.99004845e+01 3.82881740e+01\n 0.00000000e+00 0.00000000e+00 7.05429113e+01 2.11491012e+00\n 9.43219332e+01 1.15273775e-02 0.00000000e+00 0.00000000e+00\n 5.00952139e+01 2.54806759e+01 1.42653352e+01 6.90930553e+01\n 7.52728999e+01 0.00000000e+00 2.13184651e-01 4.38524590e+01\n 3.22927879e-01 0.00000000e+00]",
        "aa": 31.203949747076788,
        "kappa": 27.155831421710154
    }
}