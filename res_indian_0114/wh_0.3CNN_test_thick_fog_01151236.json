{
    "eval_time": 95.96325707435608,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.3_pc",
            "patch_size": 21,
            "serve_patch_size": 21,
            "batch_size": 32,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "append_dim": false,
            "spectral_size": 270,
            "random_rotate": true,
            "noise_type": "thick_fog"
        },
        "net": {
            "trainer": "CNN",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 60,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.3CNN",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.3CNN",
        "path_res": "./res_indian_0114/wh_0.3CNN_test_thick_fog_01151236",
        "path_pic": "./res_indian_0114/wh_0.3CNN_test_thick_fog_01151236.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.0077    0.0073    0.0075      9828\n           1     0.0321    0.7343    0.0615      2458\n           2     0.0168    0.0010    0.0020     15274\n           3     0.9951    0.0108    0.0213    114299\n           4     0.0000    0.0000    0.0000      4352\n           5     0.0007    0.0000    0.0001     31189\n           6     0.0000    0.0000    0.0000     16872\n           7     0.0000    0.0000    0.0000      2837\n           8     0.0054    0.0199    0.0086      7573\n           9     0.0000    0.0000    0.0000      8675\n          10     0.0000    0.0000    0.0000      7710\n          11     0.0000    0.0000    0.0000      6267\n          12     0.9666    0.0275    0.0536     15754\n          13     1.0000    0.0091    0.0181      5149\n          14     0.0000    0.0000    0.0000       701\n          15     0.0371    0.9919    0.0715      5083\n          16     0.0198    0.2971    0.0372      2107\n          17     0.0000    0.0000    0.0000      2251\n          18     0.0365    0.0335    0.0349      6098\n          19     0.0000    0.0000    0.0000      2440\n          20     0.0000    0.0000    0.0000       929\n          21     0.0000    0.0000    0.0000      2828\n\n    accuracy                         0.0356    270674\n   macro avg     0.1417    0.0969    0.0144    270674\nweighted avg     0.4989    0.0356    0.0161    270674\n",
        "oa": 3.556677035843856,
        "confusion": "[[   72  9007     0     0     0     0     0     0     0     0     0     0\n      0     0     0    86   663     0     0     0     0     0]\n [    0  1805     0     0     0     0     0     0     0     0     0     0\n      0     0     0    75   578     0     0     0     0     0]\n [    0  6752    16     0     0     0     0     0     0     0     0     0\n      0     0     0    40  8466     0     0     0     0     0]\n [ 9285 28347   917  1229     0     0     0     0 19137     0     0     0\n      3     0     0 39962 14749     0   666     2     0     2]\n [    0  3476     9     0     0     0     0     0     0     0     0     0\n      0     0     0    41   826     0     0     0     0     0]\n [    0    29     0     0     0     1     0     0     6     0     0     0\n     12     0     0 29763    67     0  1311     0     0     0]\n [    0  1557     9     0     0     0     0     0  2350     0     0     0\n      0     0     0 12055   901     0     0     0     0     0]\n [    0   696     0     0     0     0     0     0     0     0     0     0\n      0     0     0  2059    82     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0   151     0     0     0\n      0     0     0  7224   198     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0   859     0     0     0\n      0     0     0  7816     0     0     0     0     0     0]\n [    0   119     0     0     0     0     0     0  2371     0     0     0\n      0     0     0  5136    79     0     5     0     0     0]\n [    0   105     0     0     0   196     0     0   214     0     0     0\n      0     0     0  5618    55     0    79     0     0     0]\n [    0   521     0     6     0   719     0     0   696     0     0     0\n    434     0     0  8503  2281     0  2460   134     0     0]\n [    0   463     0     0     0     0     0     0    44    18     0     0\n      0    47     0  4060   513     0     4     0     0     0]\n [    0    25     0     0     0     0     0     0     0     0     0     0\n      0     0     0   320   356     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0  5042    41     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0  1481   626     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0   621     0     0     0\n      0     0     0   766     0     0   864     0     0     0]\n [    0     0     0     0     0   533     0     0   578     0     0     0\n      0     0     0  4767    16     0   204     0     0     0]\n [    0   418     0     0     0     0     0     0   710     0     0     0\n      0     0     0   381   931     0     0     0     0     0]\n [    0   842     0     0     0     0     0     0     0     0     0     0\n      0     0     0     2    85     0     0     0     0     0]\n [    0  2092     0     0     0     0     0     0     0     0     0     0\n      0     0     0   695    41     0     0     0     0     0]]",
        "each_acc": "[7.32600733e-01 7.34336859e+01 1.04753175e-01 1.07525000e+00\n 0.00000000e+00 3.20625862e-03 0.00000000e+00 0.00000000e+00\n 1.99392579e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 2.75485591e+00 9.12798602e-01 0.00000000e+00 9.91933897e+01\n 2.97104888e+01 0.00000000e+00 3.34535913e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00]",
        "aa": 9.69365064108346,
        "kappa": 1.6226821352859688
    }
}