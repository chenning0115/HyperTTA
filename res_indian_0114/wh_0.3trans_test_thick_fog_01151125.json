{
    "eval_time": 151.10960054397583,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.3_pc",
            "patch_size": 21,
            "serve_patch_size": 21,
            "batch_size": 32,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "append_dim": false,
            "spectral_size": 270,
            "random_rotate": true,
            "noise_type": "thick_fog"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 60,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.3trans",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.3trans",
        "path_res": "./res_indian_0114/wh_0.3trans_test_thick_fog_01151125",
        "path_pic": "./res_indian_0114/wh_0.3trans_test_thick_fog_01151125.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000      9828\n           1     0.0028    0.0651    0.0054      2458\n           2     0.0000    0.0000    0.0000     15274\n           3     0.9981    0.0321    0.0623    114299\n           4     0.0000    0.0000    0.0000      4352\n           5     0.6716    0.1114    0.1910     31189\n           6     0.0000    0.0000    0.0000     16872\n           7     0.0000    0.0000    0.0000      2837\n           8     0.1147    0.8514    0.2022      7573\n           9     0.0000    0.0000    0.0000      8675\n          10     0.0000    0.0000    0.0000      7710\n          11     0.0000    0.0000    0.0000      6267\n          12     0.5949    0.0133    0.0261     15754\n          13     0.0000    0.0000    0.0000      5149\n          14     0.0000    0.0000    0.0000       701\n          15     0.9170    0.1477    0.2545      5083\n          16     0.0182    1.0000    0.0357      2107\n          17     0.0000    0.0000    0.0000      2251\n          18     0.1989    0.0116    0.0220      6098\n          19     0.0035    0.0033    0.0034      2440\n          20     0.0000    0.0000    0.0000       929\n          21     0.0000    0.0000    0.0000      2828\n\n    accuracy                         0.0624    270674\n   macro avg     0.1600    0.1016    0.0365    270674\nweighted avg     0.5586    0.0624    0.0611    270674\n",
        "oa": 6.2440426490907885,
        "confusion": "[[    0  1637     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0  8191     0     0     0     0     0]\n [    0   160     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0  2298     0     0     0     0     0]\n [    0  2440     0     0     0     0     0     0   152     0     0     0\n      6     0     0     0 12597     0     0    79     0     0]\n [28835 46065     0  3673     0     0     0     0 26682     0     0     0\n      0     0     0     0  8482     0    22   539     0     1]\n [    9  2944     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0  1399     0     0     0     0     0]\n [    0     0     0     0     0  3473     0     0   561     0     0     0\n      0     0     0     0 27099     0    56     0     0     0]\n [    0   770     0     0     0     0     0     0  7604     0     0     0\n      0     0     0     0  8498     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0  2837     0     0     0     0     0]\n [    0   322     0     0     0     0     0     0  6448     0     0     0\n      0     0     0     0   803     0     0     0     0     0]\n [    0   326     0     0     0    92     0     0  3726     0     0     0\n     10     0     0    10  4467     0    44     0     0     0]\n [    0   565     0     0     0     0     0     0  2878     0     0     0\n      0     0     0     0  4267     0     0     0     0     0]\n [    0   499     0     0     0     0     0     0   858     0     0     0\n     30     0     0     0  4797     0    83     0     0     0]\n [    6   307     0     7     0   957     0     1   677     0    41    50\n    210     0     0    58 11670    49    77  1644     0     0]\n [    0    64     0     0     0   649     0     0     5     0     0     0\n     90     0     0     0  4341     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0    48     0     0     0\n      0     0     0     0   653     0     0     0     0     0]\n [    0    67     0     0     0     0     0     0     0     0     0     0\n      0     0     0   751  4265     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0  2107     0     0     0     0     0]\n [    0     0     0     0     0     0     0     0  2007     0     0     0\n      0     0     0     0   238     0     4     0     0     2]\n [    0   119     0     0     0     0     0     0  2263     0     0     0\n      7     0     0     0  3638     0    71     0     0     0]\n [    0     0     0     0     0     0     0     0  1010     0     0     0\n      0     0     0     0  1422     0     0     8     0     0]\n [    0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0   929     0     0     0     0     0]\n [    0   495     0     0     0     0     0     0  1276     0     0     0\n      0     0     0     0  1057     0     0     0     0     0]]",
        "each_acc": "[  0.           6.5093572    0.           3.21350143   0.\n  11.13533618   0.           0.          85.14459263   0.\n   0.           0.           1.33299479   0.           0.\n  14.77473933 100.           0.           1.16431617   0.32786885\n   0.           0.        ]",
        "aa": 10.163759390145707,
        "kappa": 4.025891461244435
    }
}