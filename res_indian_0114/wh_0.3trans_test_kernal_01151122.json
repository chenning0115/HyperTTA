{
    "eval_time": 165.6795220375061,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.3_pc",
            "patch_size": 21,
            "serve_patch_size": 21,
            "batch_size": 32,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "append_dim": false,
            "spectral_size": 270,
            "random_rotate": true,
            "noise_type": "kernal"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 60,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.3trans",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.3trans",
        "path_res": "./res_indian_0114/wh_0.3trans_test_kernal_01151122",
        "path_pic": "./res_indian_0114/wh_0.3trans_test_kernal_01151122.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     1.0000    0.1898    0.3190      9828\n           1     0.3487    0.5862    0.4373      2458\n           2     0.0930    0.9883    0.1700     15274\n           3     0.9771    0.0321    0.0622    114299\n           4     0.0000    0.0000    0.0000      4352\n           5     0.0000    0.0000    0.0000     31189\n           6     0.5352    0.1150    0.1893     16872\n           7     0.0000    0.0000    0.0000      2837\n           8     1.0000    0.4742    0.6433      7573\n           9     0.0000    0.0000    0.0000      8675\n          10     0.0000    0.0000    0.0000      7710\n          11     1.0000    0.0006    0.0013      6267\n          12     0.5217    0.3253    0.4007     15754\n          13     0.9509    0.4659    0.6254      5149\n          14     0.0000    0.0000    0.0000       701\n          15     0.0000    0.0000    0.0000      5083\n          16     0.2964    0.9981    0.4571      2107\n          17     0.0000    0.0000    0.0000      2251\n          18     1.0000    0.0753    0.1400      6098\n          19     0.0132    0.0102    0.0115      2440\n          20     0.0012    0.0861    0.0023       929\n          21     0.0000    0.0000    0.0000      2828\n\n    accuracy                         0.1396    270674\n   macro avg     0.3517    0.1976    0.1572    270674\nweighted avg     0.6152    0.1396    0.1233    270674\n",
        "oa": 13.963661083074102,
        "confusion": "[[  1865   2214   5585      0      0      0      2      0      0      0\n       0      0    160      0      0      0      2      0      0      0\n       0      0]\n [     0   1441   1007      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n      10      0]\n [     0    132  15095      0      0      0      0      0      0      0\n       0      0      1      0      0      0      0      0      0      0\n      46      0]\n [     0      1 109588   3669      0      0    186      0      0      0\n       0      0      7      0      0      0      0      0      0      5\n     843      0]\n [     0     19   2056      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n    2277      0]\n [     0      0   1845      0      0      0      0      0      0      0\n       0      0   1237      0      0      0      0      0      0      0\n   28107      0]\n [     0      0   2391      0      0      0   1940      0      0      0\n       1      0   1499      0      0      0      0      0      0      3\n   11038      0]\n [     0      0    893      0      0      0     11      0      0      0\n       0      0    829      0      0      0      1      0      0      0\n    1103      0]\n [     0    115   2160      0      0      0     29      0   3591      0\n       4      0     21      0      0      0     96      0      0   1424\n     133      0]\n [     0      0   1980      0      0      0     37      0      0      0\n       4      0     78     54      0      0      0      0      0      0\n    6522      0]\n [     0      0   5369      7      0      0    167      0      0      0\n       0      0    229      0      0      0      0      0      0     23\n    1915      0]\n [     0      0    854      0      0      0     26      0      0      0\n       0      4    233      6      0      0      0      0      0      0\n    5144      0]\n [     0      1   3204      0      0      0     12      0      0      0\n      41      0   5125     64      0      0     12      0      0      0\n    7295      0]\n [     0      0   1409      0      0      0      0      0      0      0\n       0      0     67   2399      0      0      0      0      0      0\n    1274      0]\n [     0      0    686      0      0      0      0      0      0      0\n       0      0     15      0      0      0      0      0      0      0\n       0      0]\n [     0    197      3      0      0      0      0      0      0      0\n       0      0      1      0      0      0   4881      0      0      0\n       1      0]\n [     0      0      4      0      0      0      0      0      0      0\n       0      0      0      0      0      0   2103      0      0      0\n       0      0]\n [     0      0     16      0      0      0      0      0      0      0\n       0      0      9      0      0      0      0      0      0      0\n    2226      0]\n [     0     13   3953      0      0      0     20      0      0      0\n       0      0    268      0      0      0      0      0    459     48\n    1337      0]\n [     0      0   2365      0      0      0      0      0      0      0\n       0      0     28      0      0      0      0      0      0     25\n      22      0]\n [     0      0    849      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n      80      0]\n [     0      0    996     79      0      0   1195      0      0      0\n       0      0     17      0      0      0      0      0      0    365\n     176      0]]",
        "each_acc": "[1.89763940e+01 5.86248983e+01 9.88280739e+01 3.21000184e+00\n 0.00000000e+00 0.00000000e+00 1.14983404e+01 0.00000000e+00\n 4.74184603e+01 0.00000000e+00 0.00000000e+00 6.38263922e-02\n 3.25314206e+01 4.65915712e+01 0.00000000e+00 0.00000000e+00\n 9.98101566e+01 0.00000000e+00 7.52705805e+00 1.02459016e+00\n 8.61141012e+00 0.00000000e+00]",
        "aa": 19.759827356311632,
        "kappa": 9.930991309821257
    }
}