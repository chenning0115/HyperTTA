{
    "eval_time": 176.03796648979187,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.3_pc",
            "patch_size": 21,
            "serve_patch_size": 21,
            "batch_size": 32,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "append_dim": false,
            "spectral_size": 270,
            "random_rotate": true,
            "noise_type": "poisson"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 60,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.3trans",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.3trans",
        "path_res": "./res_indian_0114/wh_0.3trans_test_poisson_01151128",
        "path_pic": "./res_indian_0114/wh_0.3trans_test_poisson_01151128.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     1.0000    0.5828    0.7364      9828\n           1     0.5524    0.6688    0.6051      2458\n           2     0.0959    0.9932    0.1750     15274\n           3     1.0000    0.0009    0.0018    114299\n           4     0.0000    0.0000    0.0000      4352\n           5     0.0000    0.0000    0.0000     31189\n           6     0.8900    0.1366    0.2369     16872\n           7     0.8500    0.0060    0.0119      2837\n           8     1.0000    0.2324    0.3772      7573\n           9     0.0000    0.0000    0.0000      8675\n          10     0.0078    0.0004    0.0007      7710\n          11     0.2308    0.0005    0.0010      6267\n          12     0.2840    0.8517    0.4259     15754\n          13     0.9090    0.1979    0.3250      5149\n          14     0.0000    0.0000    0.0000       701\n          15     0.9984    0.5981    0.7480      5083\n          16     0.5260    0.9350    0.6733      2107\n          17     0.0000    0.0000    0.0000      2251\n          18     1.0000    0.0002    0.0003      6098\n          19     0.0098    0.0381    0.0156      2440\n          20     0.0055    0.2045    0.0108       929\n          21     0.0000    0.0000    0.0000      2828\n\n    accuracy                         0.1717    270674\n   macro avg     0.4254    0.2476    0.1975    270674\nweighted avg     0.6462    0.1717    0.1188    270674\n",
        "oa": 17.165667925253256,
        "confusion": "[[  5728   1022   2952      0      0      0     20      0      0      0\n       0      0     99      0      0      0      0      0      0      2\n       5      0]\n [     0   1644    814      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [     0     12  15170      0      0      0      0      0      0      0\n       0      0     33      0      0      0      0      0      0      0\n      59      0]\n [     0      4 114064    102      0      0      0      0      0      0\n       0      0     24      0      0      0      0      0      0      0\n     105      0]\n [     0      3   3914      0      0      0      0      0      0      0\n       0      0     14      0      0      0      0      0      0      0\n     421      0]\n [     0      0     25      0      0      0      0      0      0      0\n       0      0  14309      2      0      0      0      0      0      0\n   16853      0]\n [     0     10   6109      0      0      0   2305      0      0      0\n       2      0   5693      0      0      0      0      0      0    662\n    2091      0]\n [     0     14    737      0      0      0      0     17      0      0\n       0      0   1544     16      0      0      0      0      0      0\n     509      0]\n [     0    156    873      0      0      0      1      0   1760      0\n       0      0     49      0      0      5      1      0      0   4633\n      95      0]\n [     0      0    201      0      0      0    124      2      0      0\n     376      0   4117     75      0      0      0      0      0     13\n    3767      0]\n [     0      0   3748      0      0      0     33      0      0      0\n       3      0   1558      0      0      0      0      0      0    950\n    1418      0]\n [     0      0    341      0      0      1     53      0      0      0\n       0      3   2545      2      0      0      0      0      0      0\n    3322      0]\n [     0      3    487      0      0      0     47      0      0      0\n       6      0  13418      6      0      0      0      0      0      0\n    1787      0]\n [     0      0    488      0      0      0      0      0      0      0\n       0      0    610   1019      0      0      0      0      0      0\n    3032      0]\n [     0      0    701      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [     0     87    111      0      0     13      0      1      0      0\n       0     10     31      1      0   3040   1774      0      0      6\n       9      0]\n [     0     21     76      0      0      0      0      0      0      0\n       0      0      6      0      0      0   1970      0      0      0\n      34      0]\n [     0      0     99      0      0      0      0      0      0      0\n       0      0   1954      0      0      0      0      0      0      1\n     197      0]\n [     0      0   1570      0      0      0      3      0      0      0\n       0      0   1190      0      0      0      0      0      1   2965\n     369      0]\n [     0      0   2285      0      0      0      0      0      0      0\n       0      0     55      0      0      0      0      0      0     93\n       7      0]\n [     0      0    739      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n     190      0]\n [     0      0   2633      0      0      0      4      0      0      0\n       0      0      2      0      0      0      0      0      0    188\n       1      0]]",
        "each_acc": "[5.82824583e+01 6.68836452e+01 9.93191044e+01 8.92396259e-02\n 0.00000000e+00 0.00000000e+00 1.36616880e+01 5.99224533e-01\n 2.32404595e+01 0.00000000e+00 3.89105058e-02 4.78697942e-02\n 8.51720198e+01 1.97902505e+01 0.00000000e+00 5.98072005e+01\n 9.34978643e+01 0.00000000e+00 1.63988193e-02 3.81147541e+00\n 2.04520990e+01 0.00000000e+00]",
        "aa": 24.759541282082363,
        "kappa": 13.15955299913395
    }
}