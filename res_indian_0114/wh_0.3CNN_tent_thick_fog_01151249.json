{
    "train_oa": {
        "type": "index_value",
        "index": [
            1,
            2
        ],
        "value": [
            29.15462881547544,
            30.05571277625483
        ]
    },
    "train_aa": {
        "type": "index_value",
        "index": [
            1,
            2
        ],
        "value": [
            9.197030761005864,
            9.033109419351069
        ]
    },
    "train_kappa": {
        "type": "index_value",
        "index": [
            1,
            2
        ],
        "value": [
            6.875038590654303,
            6.774971999113677
        ]
    },
    "eval_time": 343.4286196231842,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.3_pc",
            "patch_size": 21,
            "serve_patch_size": 21,
            "batch_size": 32,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "append_dim": false,
            "spectral_size": 270,
            "random_rotate": true,
            "noise_type": "thick_fog"
        },
        "net": {
            "trainer": "CNN",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 60,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.3CNN",
        "train_sign": "tent",
        "path_model_save": "./save_models/wh_0.3CNN",
        "path_res": "./res_indian_0114/wh_0.3CNN_tent_thick_fog_01151249",
        "path_pic": "./res_indian_0114/wh_0.3CNN_tent_thick_fog_01151249.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.1589    0.0634    0.0906      9828\n           1     0.0685    0.0854    0.0760      2458\n           2     0.0580    0.0099    0.0169     15274\n           3     0.4446    0.5530    0.4929    114299\n           4     0.0178    0.0076    0.0106      4352\n           5     0.2552    0.2517    0.2534     31189\n           6     0.1335    0.1361    0.1348     16872\n           7     0.0169    0.0025    0.0043      2837\n           8     0.1897    0.0631    0.0947      7573\n           9     0.2364    0.0635    0.1001      8675\n          10     0.0825    0.0389    0.0529      7710\n          11     0.0392    0.0152    0.0219      6267\n          12     0.0984    0.1986    0.1316     15754\n          13     0.1711    0.0425    0.0681      5149\n          14     0.1882    0.0456    0.0735       701\n          15     0.2277    0.0517    0.0843      5083\n          16     0.0074    0.0009    0.0017      2107\n          17     0.0366    0.0258    0.0302      2251\n          18     0.1253    0.2811    0.1734      6098\n          19     0.0057    0.0143    0.0081      2440\n          20     0.0000    0.0000    0.0000       929\n          21     0.0676    0.0364    0.0473      2828\n\n    accuracy                         0.3006    270674\n   macro avg     0.1195    0.0903    0.0894    270674\nweighted avg     0.2694    0.3006    0.2742    270674\n",
        "oa": 30.05571277625483,
        "confusion": "[[  623   127    90  6288   120   643   246    11    43    60    92    21\n    844    37     4    73     6    12   360   105     3    20]\n [   25   210    21  1194   107   191   114     6    17    10    20     9\n    224    19     0    92    68     3    52    55    14     7]\n [  112   151   151 11480   118  1061   207    20   100    15   143    41\n    881    18     6    40     1    33   479   205     4     8]\n [ 2167  1259  1387 63205   542 10444  6982   114  1004   460  1767   638\n  12638   354    66   318   118   986  5327  3679   104   740]\n [   49    48    18  2947    33   300   102     7     0    17    55    25\n    499    12     1     5     4     3   117    93     7    10]\n [  309   106   236 13286   160  7849  1209    32   339   361   356   466\n   3970   178     5   147    23   147  1696   294     1    19]\n [   84   130    93  7489   162  1606  2296    51   113   214   195   359\n   2629   120     6    40     6    37   711   258     6   267]\n [   27     5    13  1392    16   519   178     7    19    26    26    49\n    400    55     2    15     7     1    69     5     0     6]\n [   50   240    52  3037    55   709   924     5   478   121   138    23\n    577    10     4    28     3    14   619   345     1   140]\n [   84    58   120  3248    25  1218   974    32    84   551    84    81\n   1302   128    15    27     7    36   444   143     1    13]\n [   74    69    43  3730    20  1046   678     3    54   144   300   118\n    609    37     6    25     1    31   566   102     0    54]\n [   41    34    13  2817    11   874   740    12    14    41    47    95\n    993    27     1    13     3    37   344    72     0    38]\n [   95   120   192  8785   203  1643   301    40    38    68   107   195\n   3129    40     7    38     6   120   441   164    12    10]\n [   42    17    28  2062    54   414   491    46    14   150    37   145\n   1280   219     1     9     9    13    99     8     2     9]\n [    3     3     7   473     5    18    24     0     4     0    14     0\n     50     0    32     0     0     1    61     4     0     2]\n [   26   197    36  2346   123   870    97    21    48    17    29    33\n    694    12     2   263     4    22   174    64     1     4]\n [   18   128    43  1094    23   143    43     2     2    12    28    15\n    493     6     0     3     2     5    24    21     0     2]\n [    6    10     5  1566     0    32   218     0     7     5    86    34\n      9     0     7     0     0    58   150    40     0    18]\n [   63    62    19  1760    34   774   905     2    86    24    66    55\n    245     4     5    10     1    20  1714   195     1    53]\n [   14    41    12  1788    10   140    73     1    16     3    15     9\n    204     1     0     7     1     4    66    35     0     0]\n [    1     2     6   820    27    15     2     0     0     1     2     2\n     19     0     0     0     0     0     4    28     0     0]\n [    7    49    18  1352     1   243   394     1    40    31    31    12\n    104     3     0     2     0     1   159   277     0   103]]",
        "each_acc": "[ 6.33903134  8.54353133  0.98860809 55.29794661  0.75827206 25.16592388\n 13.60834519  0.24673951  6.31189753  6.35158501  3.89105058  1.51587682\n 19.86162245  4.25325306  4.56490728  5.17410978  0.09492169  2.57663261\n 28.10757625  1.43442623  0.          3.64214993]",
        "aa": 9.033109419351069,
        "kappa": 6.774971999113677
    }
}