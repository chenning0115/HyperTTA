{
    "eval_time": 95.89115571975708,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.3_pc",
            "patch_size": 21,
            "serve_patch_size": 21,
            "batch_size": 32,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "append_dim": false,
            "spectral_size": 270,
            "random_rotate": true,
            "noise_type": "kernal"
        },
        "net": {
            "trainer": "CNN",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 60,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.3CNN",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.3CNN",
        "path_res": "./res_indian_0114/wh_0.3CNN_test_kernal_01151235",
        "path_pic": "./res_indian_0114/wh_0.3CNN_test_kernal_01151235.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.9843    0.5406    0.6979      9828\n           1     0.0718    0.9963    0.1339      2458\n           2     0.5312    0.2813    0.3678     15274\n           3     0.9784    0.9394    0.9585    114299\n           4     0.7745    0.1650    0.2720      4352\n           5     0.0000    0.0000    0.0000     31189\n           6     0.8020    0.2396    0.3690     16872\n           7     0.9324    0.0243    0.0474      2837\n           8     0.8924    0.0186    0.0365      7573\n           9     0.9545    0.0024    0.0048      8675\n          10     0.2940    0.1756    0.2199      7710\n          11     0.0000    0.0000    0.0000      6267\n          12     0.1458    0.8128    0.2473     15754\n          13     0.0686    0.0072    0.0130      5149\n          14     1.0000    0.0029    0.0057       701\n          15     0.5057    0.2520    0.3364      5083\n          16     0.3342    0.9397    0.4930      2107\n          17     0.0000    0.0000    0.0000      2251\n          18     0.0310    0.0123    0.0176      6098\n          19     0.0426    0.0357    0.0388      2440\n          20     0.0000    0.0000    0.0000       929\n          21     0.9940    0.1174    0.2100      2828\n\n    accuracy                         0.5260    270674\n   macro avg     0.4699    0.2529    0.2032    270674\nweighted avg     0.6516    0.5260    0.5151    270674\n",
        "oa": 52.60017585730436,
        "confusion": "[[  5313   2758   1529     11      0      0      0      0      0      0\n       0      0    217      0      0      0      0      0      0      0\n       0      0]\n [     0   2449      3      0      0      0      0      0      0      0\n       0      0      0      0      0      0      6      0      0      0\n       0      0]\n [     0  10786   4297      0      0      0      0      0      0      0\n       0      0     28    161      0      0      1      0      0      0\n       1      0]\n [     0   4439   1250 107371    120      0      0      0      0      0\n       0      0    134     66      0      0      0      0      0     76\n     843      0]\n [    85   2264    775    317    718      0      0      0      0      0\n       0      0     81     69      0      0      0      0      0      0\n      43      0]\n [     0    211      0      1      0      0      0      0      0      0\n       0      0  30527      0      0      0    430      0      0     20\n       0      0]\n [     0     59      4     29      0      0   4043      0      0      0\n     168      0  12535      2      0      0      0      0      0     31\n       1      0]\n [     0    608     80      0      0      0    102     69      0      0\n       0      0   1924      0      0      0     38      0      0     16\n       0      0]\n [     0   3655     24      0      0      0     76      0    141      0\n      70      0   3374      0      0     67      0      0      0    164\n       0      2]\n [     0      0      0      1      0      0     19      0      0     21\n      31      0   8603      0      0      0      0      0      0      0\n       0      0]\n [     0     17     34     14     70      0    452      0      0      0\n    1354      0   3129      0      0      0      0      0   2162    444\n      34      0]\n [     0     99      0     28      0      0      8      0      0      1\n    1109      0   5020      2      0      0      0      0      0      0\n       0      0]\n [     0   2516     92     69      0      0      0      5      0      0\n       0      0  12805    188      0      7     72      0      0      0\n       0      0]\n [     0   1493      0      0      0      0      0      0      0      0\n       0      0   3619     37      0      0      0      0      0      0\n       0      0]\n [     0      2      1      0      0      0    264      0      0      0\n       0      0     72      0      2      0      0      0    173    187\n       0      0]\n [     0    324      0      0      0      0      0      0      0      0\n       0      0     76      4      0   1281   3398      0      0      0\n       0      0]\n [     0    126      0      0      0      0      0      0      0      0\n       0      0      0      1      0      0   1980      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      0      0\n     664      0   1587      0      0      0      0      0      0      0\n       0      0]\n [     0     64      0    264     19      0     14      0      0      0\n    1210      0   2879      0      0   1178      0      0     75    395\n       0      0]\n [     0   1325      0      0      0      0      0      0     17      0\n       0      0   1004      0      0      0      0      0      7     87\n       0      0]\n [     0    913      0      0      0      0      0      0      0      0\n       0      0      7      9      0      0      0      0      0      0\n       0      0]\n [     0      0      0   1632      0      0     63      0      0      0\n       0      0    180      0      0      0      0      0      0    621\n       0    332]]",
        "each_acc": "[54.05982906 99.63384866 28.13277465 93.93870463 16.49816176  0.\n 23.96277857  2.43214663  1.86187772  0.24207493 17.5616083   0.\n 81.28094452  0.71858613  0.2853067  25.20165257 93.97247271  0.\n  1.22991145  3.56557377  0.         11.7397454 ]",
        "aa": 25.28718173494547,
        "kappa": 41.042479515252225
    }
}