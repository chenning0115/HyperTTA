{
    "eval_time": 177.77331018447876,
    "param": {
        "data": {
            "data_sign": "WH",
            "data_file": "WH_0.3_pc",
            "patch_size": 21,
            "serve_patch_size": 21,
            "batch_size": 32,
            "num_classes": 22,
            "pca": -1,
            "dim_heads": 64,
            "append_dim": false,
            "spectral_size": 270,
            "random_rotate": true,
            "noise_type": "stripes"
        },
        "net": {
            "trainer": "transformer",
            "use_mask": true,
            "mlp_head_dim": 64,
            "depth": 3,
            "dim": 64,
            "heads": 20,
            "kernal": 3,
            "padding": 1
        },
        "train": {
            "epochs": 60,
            "lr": 0.001,
            "weight_decay": 0
        },
        "uniq_name": "wh_0.3trans",
        "train_sign": "test",
        "path_model_save": "./save_models/wh_0.3trans",
        "path_res": "./res_indian_0114/wh_0.3trans_test_stripes_01151131",
        "path_pic": "./res_indian_0114/wh_0.3trans_test_stripes_01151131.png"
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.8524    0.9957    0.9185      9828\n           1     0.7884    0.9943    0.8795      2458\n           2     0.9883    0.9161    0.9508     15274\n           3     0.9926    0.9839    0.9882    114299\n           4     0.9863    0.8950    0.9384      4352\n           5     0.9167    0.9973    0.9553     31189\n           6     0.9618    0.8085    0.8785     16872\n           7     0.7546    0.9746    0.8506      2837\n           8     0.9816    0.9982    0.9898      7573\n           9     0.7964    0.9859    0.8811      8675\n          10     0.8137    0.8538    0.8333      7710\n          11     0.9869    0.4940    0.6584      6267\n          12     0.9420    0.8042    0.8677     15754\n          13     0.9979    0.5551    0.7133      5149\n          14     0.9241    0.9900    0.9559       701\n          15     0.9806    0.9953    0.9879      5083\n          16     0.9790    0.9725    0.9757      2107\n          17     0.4136    0.9956    0.5844      2251\n          18     0.8435    0.9690    0.9019      6098\n          19     0.9093    0.8672    0.8878      2440\n          20     0.9352    0.3262    0.4836       929\n          21     0.7361    0.9993    0.8478      2828\n\n    accuracy                         0.9333    270674\n   macro avg     0.8855    0.8805    0.8604    270674\nweighted avg     0.9451    0.9333    0.9324    270674\n",
        "oa": 93.32591974109076,
        "confusion": "[[  9786     42      0      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      0\n       0      0]\n [     1   2444     10      0      0      0      0      0      0      0\n       0      0      0      0      0      0      0      0      0      3\n       0      0]\n [   127    566  13993    290     17      3      1     62      0      1\n       0      0     35      1     15      4     16      0      2    121\n      20      0]\n [  1086      2      0 112463     36      0      0      0      4      0\n     139      0      0      0      0      0      0     54     16      7\n       0    492]\n [   344      5      0    100   3895      0      0      0      0      0\n       8      0      0      0      0      0      0      0      0      0\n       0      0]\n [     0      0      0      0      0  31106      0      2      0     40\n       0      0      2      0      0      2      0     23     14      0\n       0      0]\n [     7      2      8     36      0     11  13641     11    117    241\n     807     13     13      5     12      0      0   1290    276      5\n       0    377]\n [     0      0      0      3      0      2     15   2765      0     33\n       1      3      3      0      2      0      0      6      0      0\n       0      4]\n [     0      0      1      0      0      0      0      0   7559      0\n       4      0      0      0      0      0      0      0      9      0\n       0      0]\n [     0      0      0      6      0      4      0      0      1   8553\n      24      0      0      0      0      0      0     80      7      0\n       0      0]\n [    40      0      0      4      0     18    240      0      0    738\n    6583      0      0      0     13      0      0     53     17      2\n       0      2]\n [     1      0     11      0      0    349    149    261      0    217\n     160   3096    689      0      8     31      2    818    459      6\n       0     10]\n [    79      0      9    227      1   1009     66    249      0     72\n     233     24  12670      0      0     54      8    816    171     45\n       0     21]\n [     0      0      0      0      0   1414     14     61      0    799\n       0      0      1   2858      0      0      0      2      0      0\n       0      0]\n [     0      0      0      0      0      0      5      0      1      0\n       1      0      0      0    694      0      0      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      6      0\n       0      0      0      0      0   5059     18      0      0      0\n       0      0]\n [     2     37      0      0      0      0      0      0      0      0\n       0      0     10      0      0      9   2049      0      0      0\n       0      0]\n [     0      0      0      0      0      0      0      0      0      8\n       0      0      0      0      0      0      0   2241      0      0\n       0      2]\n [     8      0      0      0      0     16      7      0     11     38\n      66      0      0      0      0      0      0     35   5909      0\n       1      7]\n [     0      0      0     17      0      2     39     10      2      0\n      24      0      0      0      7      0      0      0    125   2116\n       0     98]\n [     0      2    127    160      0      0      6    243      0      0\n      38      1     27      0      0      0      0      0      0     22\n     303      0]\n [     0      0      0      0      0      0      0      0      0      0\n       2      0      0      0      0      0      0      0      0      0\n       0   2826]]",
        "each_acc": "[99.57264957 99.43043124 91.6131989  98.39368673 89.49908088 99.73388053\n 80.84992888 97.46210786 99.81513271 98.59365994 85.38261997 49.40162757\n 80.4240193  55.50592348 99.00142653 99.52783789 97.247271   99.555753\n 96.90062316 86.72131148 32.61571582 99.92927864]",
        "aa": 88.05350750458533,
        "kappa": 91.582299919024
    }
}